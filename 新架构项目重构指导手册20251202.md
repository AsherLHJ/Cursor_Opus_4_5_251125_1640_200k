# 新架构项目重构指导手册

**版本：2025-12-02**

---

## 目录

- [1. 用户注册和登录](#1-用户注册和登录)
  - [1.1 数据访问策略](#11-数据访问策略)
  - [1.2 表 user_info 结构](#12-表-user_info-结构)
  - [1.3 Redis 存储方式](#13-redis-存储方式)
  - [1.4 用户 Token 认证机制](#14-用户-token-认证机制)
- [2. 用户登录后，主页刷新历史记录](#2-用户登录后主页刷新历史记录)
- [3. 获取导航栏显示的用户余额](#3-获取导航栏显示的用户余额)
- [4. 加载主页筛选面板的学科标签](#4-加载主页筛选面板的学科标签)
  - [4.1 表 info_paper_with_tag 结构](#41-表-info_paper_with_tag-结构)
  - [4.2 表 info_tag 结构](#42-表-info_tag-结构)
  - [4.3 Redis 存储方式](#43-redis-存储方式)
- [5. 根据标签筛选并返回期刊列表](#5-根据标签筛选并返回期刊列表)
  - [5.1 表 contentlist 结构](#51-表-contentlist-结构)
  - [5.2 Redis 存储方式](#52-redis-存储方式)
- [6. 估算选中期刊和年份的文献总数及费用](#6-估算选中期刊和年份的文献总数及费用)
  - [6.1 新增表 contentlist_year_number](#61-新增表-contentlist_year_number)
- [7. 用户正式提交任务](#7-用户正式提交任务)
  - [7.1 任务队列结构](#71-任务队列结构)
- [8. 任务分发线程与工人线程执行](#8-任务分发线程与工人线程执行)
  - [8.1 系统资源计算器](#81-系统资源计算器)
  - [8.2 查询任务执行规则](#82-查询任务执行规则)
  - [8.3 表 paperinfo 重构](#83-表-paperinfo-重构)
  - [8.4 Block 存储方案](#84-block-存储方案)
- [9. 任务结果的持久化与下载流程](#9-任务结果的持久化与下载流程)
  - [9.1 持久化策略](#91-持久化策略)
  - [9.2 下载任务的消息队列](#92-下载任务的消息队列)
  - [9.3 下载流程详解](#93-下载流程详解)
  - [9.4 Redis Key 设计](#94-redis-key-设计)
  - [9.5 性能优化：批量获取](#95-性能优化批量获取)
  - [9.6 高并发场景分析](#96-高并发场景分析)
  - [9.7 API 接口设计](#97-api-接口设计)
- [9.5 API 请求 Token 认证规范（修复37新增）](#95-api-请求-token-认证规范修复37新增)
- [9.6 公告栏与维护模式（修复35新增）](#96-公告栏与维护模式修复35新增)
- [10. 安全与多用户隔离设计（安全修正案）](#10-安全与多用户隔离设计安全修正案)
  - [10.1 Redis Key 命名空间隔离](#101-redis-key-命名空间隔离)
  - [10.2 下载权限强校验](#102-下载权限强校验)
- [11. 高效余额扣费与持久化设计（Billing System）](#11-高效余额扣费与持久化设计billing-system)
  - [11.1 数据准备](#111-数据准备)
  - [11.2 消费流水队列](#112-消费流水队列)
  - [11.3 后台对账线程](#113-后台对账线程)
- [12. 废弃功能与变更说明](#12-废弃功能与变更说明)
- [13. 任务暂停与恢复设计](#13-任务暂停与恢复设计)
  - [13.1 信号灯设计](#131-信号灯设计)
  - [13.2 暂停流程](#132-暂停流程)
  - [13.3 恢复流程](#133-恢复流程)
  - [13.4 僵尸任务处理](#134-僵尸任务处理)
- [13.5 任务终止（Terminate）设计](#135-任务终止terminate设计)
- [14. 蒸馏任务业务全流程设计](#14-蒸馏任务业务全流程设计)
  - [14.1 数据源与复用](#141-数据源与复用)
  - [14.2 蒸馏任务队列](#142-蒸馏任务队列)
  - [14.3 流程设计](#143-流程设计)
  - [14.4 蒸馏专用 Block 设计（修复29-31新增）](#144-蒸馏专用-block-设计修复29-31新增)
  - [14.5 蒸馏费率传递优化（IOPS优化版）](#145-蒸馏费率传递优化iops优化版)
  - [14.6 DOI 反向索引（修复26新增）](#146-doi-反向索引修复26新增)
- [15. 部署架构与网络拓扑](#15-部署架构与网络拓扑)
  - [15.1 网络架构](#151-网络架构)
  - [15.2 安全组策略](#152-安全组策略)
  - [15.3 负载均衡](#153-负载均衡)
- [16. 新版管理员系统设计](#16-新版管理员系统设计)
  - [16.1 账户隔离策略](#161-账户隔离策略)
  - [16.2 访问控制](#162-访问控制)
  - [16.3 功能模块设计](#163-功能模块设计)
  - [16.4 批量操作 API（修复32新增）](#164-批量操作-api修复32新增)
  - [16.5 DataTable 组件（修复32新增）](#165-datatable-组件修复32新增)
  - [16.6 刷新控制功能（修复33新增）](#166-刷新控制功能修复33新增)
  - [16.7 废弃项](#167-废弃项)
- [17. DB_tools 重构与数据库初始化流程](#17-db_tools-重构与数据库初始化流程)
  - [17.1 废弃说明](#171-废弃说明)
  - [17.2 新工具设计：init_database.py](#172-新工具设计init_databasepy)
  - [17.3 数据库初始化流程](#173-数据库初始化流程)
  - [17.4 关键表 SQL 定义](#174-关键表-sql-定义)
  - [17.5 AI 语言适配机制（修复36新增）](#175-ai-语言适配机制修复36新增)
  - [17.6 Redis Key 完整汇总（修复24-40更新）](#176-redis-key-完整汇总修复24-40更新)

---

## 1. 用户注册和登录

### 1.1 数据访问策略

用户注册和登录的 server 进程首先访问 Redis 中与 MySQL 的表 `user_info` 相关的数据。如果在 Redis 中没有找到，则直接访问 MySQL 进行读写，奉行 **"缓存未命中则回源 MySQL 加载"** 的策略（Lazy Loading）。

在从 MySQL 加载后，要把数据同时写入 Redis，写入 Redis 时设置一个较长的过期时间（TTL，如 8 小时）。表 `user_info` 相关的数据过期之前必须先按照以下规则同步写回 MySQL：

#### Redis 数据过期前写回 MySQL 的策略

| 类型 | 说明 |
|-----|------|
| 可被写回的数据 | `balance` |
| 不可写回的数据 | 其他所有数据 |
| 条件约束 | 只有确认了数据被成功写回 MySQL 后，Redis 中的对应数据才能成功被过期删除，否则多次尝试写回（此条件仅对"过期删除"策略有效） |

#### Redis 还未过期的数据写回 MySQL 的策略

| 类型 | 说明 |
|-----|------|
| 可被写回的数据 | `balance` |
| 不可写回的数据 | 其他所有数据 |
| 写回时机 | 该数据每次被改变（更新）之后立即写回 MySQL |

#### 本地持久化策略

Redis 中，表 `user_info` 相关的"未过期的"数据必须本地持久化，未过期期间其本地持久化的数据不能被删除，但过期后一定要删除。

> **配置开关**：需要在 `config.json` 中加一个开关，以在本地开发者模式开启时（`"local_develop_mode": true`），可以调试开启或关闭"表 `user_info` 相关的未过期的数据"的本地持久化功能（加载不同的 `docker-compose.local.yml`）。

### 1.2 表 user_info 结构

> **重要说明**：MySQL 中应当本就存在表 `user_info`。"本就存在"是因为运维人员会手动使用 `DB_tools` 目录下的工具脚本将原始数据转换并存入 MySQL 数据库，而这一步不在也不应该在生产环境的 server 进程中被自动执行。

#### 表结构定义

| Field | Type | Null | Key | Default | Extra |
|-------|------|------|-----|---------|-------|
| uid | int | NO | PRI | NULL | auto_increment |
| username | varchar(255) | NO | UNI | NULL | |
| password | varchar(255) | NO | | NULL | |
| balance | decimal(10,2) | YES | | 0.00 | |
| permission | int | YES | | 0 | |

#### 字段说明

- **uid**: 用户唯一 ID（Primary Key，自增）
- **username**: 用户登录名（Unique）
- **password**: 用户密码（存储为 bcrypt 哈希值）
- **balance**: 账户余额（用于支付检索费用）
- **permission**: 用户并发权限（允许同时使用的最大线程数）

#### 内容示例

```sql
mysql> SELECT * FROM user_info LIMIT 1;
+-----+----------+--------------------------------------------------------------+----------+------------+
| uid | username | password                                                     | balance  | permission |
+-----+----------+--------------------------------------------------------------+----------+------------+
|   1 | asher    | $2b$12$MbT8lgcjHO5Rx4HlHODxAekNQLyXDDuSp9sQp3A574rU4/M0d4d8q | 90076.00 |          2 |
+-----+----------+--------------------------------------------------------------+----------+------------+
```

### 1.3 Redis 存储方式

#### UserInfo Hash

- **Key**: `user:{uid}:info`
- **内容**: 存储 `username`, `permission` 等
- **TTL**: 8 小时，访问延期

#### Balance String/Hash

- **Key**: `user:{uid}:balance`
- **内容**: 存储当前余额
- **说明**: 独立 Key 以支持高频原子操作
- **TTL**: 8 小时

#### 读写策略

- **读操作**: 优先查 Redis，MISS 则回源 MySQL 并写入 Redis
- **写操作**（如充值）: 先更新 MySQL 再更新/删除 Redis
- **扣费操作**（高频）: 走 Billing System（见第 11 章）

### 1.4 用户 Token 认证机制（修复37新增）

用户登录成功后，后端生成安全随机 Token：

```python
token = secrets.token_urlsafe(32)
```

#### Token 存储

- **Redis Key**: `user:session:{token}` → uid
- **TTL**: 24 小时

#### 前端实现

- 前端在 `localStorage` 中保存 token
- 所有 API 请求需携带 Authorization 头：`Authorization: Bearer {token}`

#### 后端验证流程

1. 后端验证 Token 有效性后从 Redis 获取 uid
2. 不再信任前端传递的 uid 参数
3. 登出时销毁 Redis 中的会话记录

#### 安全改进

> **重要**: 修复了原有架构中 Token 生成但未验证的严重安全漏洞，现在所有需认证的 API 都会验证 Token。

---

## 2. 用户登录后，主页刷新历史记录

### Redis Key 设计

- **Key**: `user:{uid}:history`
- **类型**: ZSet
- **Score**: Timestamp
- **Member**: query_index

### 存储内容

仅存储 `query_index` 的列表。

### 加载策略

1. 优先执行 `ZREVRANGE user:{uid}:history 0 10` 获取最近的任务 ID
2. 拿着 ID 去查 `query_log` 表（或 Redis 中的 `query:{uid}:{qid}:info` 缓存）
3. 若 Redis History 为空，回源 MySQL `list_query_logs_by_uid` 并重建缓存

---

## 3. 获取导航栏显示的用户余额

如果前面的步骤"1. 用户注册和登录"已经成功进行，那进行到现在的步骤 3 时，Redis 中已经存在了与 MySQL 的表 `user_info` 相关的数据。

所以仿照步骤"1. 用户注册和登录"的方式，直接从 Redis 中读取该用户的余额 `balance` 数据。

---

## 4. 加载主页筛选面板的学科标签

> **重要说明**：MySQL 中应当本就存在表 `info_paper_with_tag` 和表 `info_tag`。"本就存在"是因为运维人员会手动使用 `DB_tools` 目录下的工具脚本将原始数据转换并存入 MySQL 数据库，而这一步不在也不应该在生产环境的 server 进程中被自动执行。

### 4.1 表 info_paper_with_tag 结构

#### 表结构定义

| Field | Type | Null | Key | Default | Extra |
|-------|------|------|-----|---------|-------|
| id | int | NO | PRI | NULL | auto_increment |
| Name | varchar(255) | NO | MUL | NULL | |
| Tag | varchar(255) | NO | MUL | NULL | |

#### 字段说明

- **id**: 映射关系唯一 ID（Primary Key，自增）
- **Name**: 期刊缩写
- **Tag**: 对应的学科标签
- **约束**: Name + Tag 组合唯一

#### 内容示例

```sql
mysql> SELECT * FROM info_paper_with_tag LIMIT 1;
+----+-------------------+------+
| id | Name              | Tag  |
+----+-------------------+------+
|  7 | ANNU REV NEUROSCI | 医学 |
+----+-------------------+------+
```

### 4.2 表 info_tag 结构

#### 表结构定义

| Field | Type | Null | Key | Default | Extra |
|-------|------|------|-----|---------|-------|
| tag | varchar(255) | NO | PRI | NULL | |
| tagtype | varchar(255) | NO | | NULL | |

#### 字段说明

- **tag**: 学科标签名（Primary Key）
- **tagtype**: 标签类型（如 "一级分类", "二级分类"）

#### 内容示例

```sql
mysql> SELECT * FROM info_tag LIMIT 1;
+----------------------+----------+
| tag                  | tagtype  |
+----------------------+----------+
| 中世纪与文艺复兴研究 | 二级分类 |
+----------------------+----------+
```

### 4.3 Redis 存储方式

Redis 容器建起后，后台进程运行脚本对 Redis 初始化，将 MySQL 中的这两个表（`info_paper_with_tag` 和 `info_tag`）存入 Redis，并本地持久化存储。

#### 标签元数据（Hash）

- **Key**: `sys:tags:info`
- **Field → Value 示例**:
  - `"医学"` → `"一级分类"`
  - `"计算机科学"` → `"一级分类"`

#### 标签-期刊反向索引（Set）

- **Key**: `sys:tag_journals:{Tag}`
- **示例**: Key `sys:tag_journals:医学` → Value: `{"ANNU REV NEUROSCI", "LANCET", ...}`

#### 设计优势

Set 结构支持 `SINTER`（交集），方便实现"医学 AND 2024"的快速筛选。

### 生产环境访问策略

在生产环境的正常业务流程中，server 进程直接访问 Redis 中 `sys:tags:info` 和 `sys:tag_journals:{Tag}` 数据（**不能访问 MySQL**），可频繁读写数据。

---

## 5. 根据标签筛选并返回期刊列表

这一步中，用户会在 index 主页中选定需要的期刊，并选定年份范围（例如 2023-2025 年）。

> **重要说明**：MySQL 中应当本就存在表 `contentlist`。"本就存在"是因为运维人员会手动使用 `DB_tools` 目录下的工具脚本将原始数据转换并存入 MySQL 数据库，而这一步不在也不应该在生产环境的 server 进程中被自动执行。

### 5.1 表 contentlist 结构

#### 表结构定义

| Field | Type | Null | Key | Default | Extra |
|-------|------|------|-----|---------|-------|
| Name | varchar(255) | NO | PRI | NULL | |
| FullName | text | YES | | NULL | |
| DataRange | text | YES | | NULL | |
| UpdateDate | text | YES | | NULL | |
| Price | int | YES | | NULL | |

#### 字段说明

- **Name**: 期刊/会议缩写（Primary Key）
- **FullName**: 期刊/会议全名
- **DataRange**: 该期刊包含的数据年份范围
- **UpdateDate**: 数据的最后更新日期
- **Price**: 该期刊每篇文章的基础检索点价格

#### 内容示例

```sql
mysql> SELECT * FROM contentlist LIMIT 1;
+-------------------+-------------------------------+-----------+------------+-------+
| Name              | FullName                      | DataRange | UpdateDate | Price |
+-------------------+-------------------------------+-----------+------------+-------+
| ANNU REV NEUROSCI | Annual Review of Neuroscience | 2016-2025 | 10/31/2025 |     2 |
+-------------------+-------------------------------+-----------+------------+-------+
```

### 5.2 Redis 存储方式

Redis 容器建起后，后台进程运行脚本对 Redis 初始化，将 MySQL 中的表 `contentlist` 存入 Redis，并本地持久化存储。

#### 期刊基础信息（Hash）

- **Key**: `sys:journals:info`
- **Field → Value 示例**: `"ANNU REV NEUROSCI"` → JSON `{"FullName":..., "DataRange":...}`

#### 期刊价格表（Hash）

- **Key**: `sys:journals:price`
- **Field → Value 示例**: `"ANNU REV NEUROSCI"` → `"2"` (Integer)

> **设计说明**: 独立存储价格是为了 Worker 扣费时能以 O(1) 极速读取，无需解析大 JSON。

### 生产环境访问策略

在生产环境的正常业务流程中，server 进程直接访问 Redis 中 `sys:journals:info` 和 `sys:journals:price` 数据（**不能访问 MySQL**），可频繁读写数据。

---

## 6. 估算选中期刊和年份的文献总数及费用

用户在完成上一步"5. 根据标签筛选并返回期刊列表"之后，紧接着在这一步中，用户会点击"更新统计"按钮。系统会从 Redis 中读取数据（**不能访问 MySQL**），然后估算选中期刊和年份的文献总数及费用。

### 6.1 新增表 contentlist_year_number

#### 设计方案

**S1）MySQL 表结构**

MySQL 中新增一个表 `contentlist_year_number`，包含 2 个列：`Name` 和 `YearNumber`。仍然和 `contentlist` 表一样以 `Name` 作为主键。而 `YearNumber` 这一列中用一个完整的字符串存储每一年包含的文献篇数信息。

**数据格式示例**:

```
2016:120,2017:252,2018:325,2019:663
```

其中，英文冒号 `:` 的左侧数字表示年份，右侧数字表示该刊物在该年份总共包含的文献篇数。

**S2）DB_TOOL 脚本**

在 `DB_TOOL` 目录中，新增一个脚本，用于将每个刊物的每个年份包含的文献篇数统计后，以上述格式记录在新增的表 `contentlist_year_number` 中。

**S3）Redis 存储**

MySQL 的表 `contentlist_year_number` 在 Redis 初始化时就要被写入 Redis。使用 String 数据格式存储每一条的整个对象。

**示例**:

```bash
SET sys:year_number:ANNU\ REV\ NEUROSCI '{"2016":"120","2017":"252","2018":"325","2019":"663"}'
```

**S4）生产环境使用**

在生产环境的正常业务流程中，server 进程直接从 Redis 的"与 MySQL 表 `contentlist_year_number` 对应"的数据中读取所选待查刊物对应的年份范围包含的总文献数量，再结合 Redis 中"与 MySQL 表 `contentlist` 对应"的数据中所选刊物的 `Price`，用以计算待查文献总篇数和消耗检索点的数量。

---

## 7. 用户正式提交任务

用户点击"开始检索"按钮以正式向服务器提交开始查询任务的请求。任务进入 Redis 的"查询任务的消息队列"。

### 7.1 任务队列结构

Redis 中应当有这么一个"查询任务的消息队列"需要被设计出来：

#### Redis Key 设计

- **Key**: `task:{uid}:{qid}:pending_blocks`
- **类型**: List
- **Value**: Block Key（例如 `meta:NATURE:2024`）

#### 作用

- 分发线程将大 Query 拆解为多个 Block Key 推入此队列
- Worker 线程从这里 `LPOP` 抢占任务

#### 设计优势

实现了任务粒度的细化和多 Worker 的负载均衡。

---

## 8. 任务分发线程与工人线程执行

server 进程中应该有以下组件：

- **查询任务分发线程**: 用于将消息队列里的查询任务分发出去的线程。只要步骤 7 中提到的 Redis 的"查询任务的消息队列"中还有任务，那么"查询任务分发线程"就应当按照"查询任务执行规则"将任务依次取出，分配给多线程并发的"工人线程"
- **工人线程生产器**: 根据"查询任务执行规则"生产"工人线程"
- **工人线程统计器**: 实时统计当前存在的工人线程数量，并拥有返回"当前存在的工人线程数量"的功能
- **TPM 累加器**: 工人线程每次收到来自远端 AI 返回的消息时，都可以通过 `tokens = response.usage.total_tokens` 获取本次对话消耗的总 token 数量。每个工人线程只要收到了本次对话消耗的总 token 数量，就应该立即将它发送给"TPM 累加器"

### 8.1 系统资源计算器

server 进程中应该有一个"系统资源计算器"来计算当前系统的：

1. **实时 TPM**: 整个系统每分钟消耗的 Token 总数（包含发送和接收的 Tokens）
2. **实时 RPM**: 整个系统每分钟向 AI 发送的请求总数

#### TPM/RPM 滑动窗口机制

实时 TPM 和实时 RPM 以"滑动窗口"的方式进行统计：

##### TPM 滑动窗口

存在一个容量为 60 个单位的队列，从队列的第一个单位（队首）开始，每单位存放 1 秒间隔内整个系统使用的总 Token 数量。

- **队列未填满时**: 队列中所有单位内存储的 token 数量之和就是当前的"系统已使用 TPM"
- **队列填满后**: 对于新来的数据，队列挤出队首单位内的数值（排出最旧的数据），剩下的队列整体向前移动一个单位，最后新数据加入队尾空出来的单位中
- **队列填满时**: 队列中所有单位内存储的 token 数量之和就是当前的"系统已使用 TPM"

##### RPM 滑动窗口

和 TPM 滑动窗口一样，但每单位的数据不一样，存放的是 1 秒间隔内整个系统向远端 AI 发送的请求总次数。

##### 滑动窗口队列示意图

```
(队首)[0-1][1-2][2-3]......[59-60](队尾)
```

### 8.2 查询任务执行规则

#### 规则 R1：任务获取与分配

如果"查询任务分发线程"要从"查询任务的消息队列"中取出一个任务（这里简称为"队首任务"），且想要开始分配该任务给工人线程，那么它必须向"工人线程生产器"请求产生工人线程。工人线程生产器收到请求后，根据"规则 R2"决定是否要生产指定数量的工人线程。

#### 规则 R2：资源检查与线程生产

只有当前系统剩余资源高于"队首任务"所需的资源时，工人线程生产器才能生产"队首任务"对应的用户（uid）所拥有的权限（permission）数值相同的工人线程。

**示例**: 假设当前系统剩余资源高于"队首任务"所需的资源，此时"队首任务"的用户的 permission 是 2，那么工人线程生产器就要生产 2 个工人线程，否则一个也不能生产。

> **补充（2025-11-27）**: 实际启动的 Worker 数量 = `min(permission, 待处理Block数量)`。当 Block 数量少于 permission 时，只启动与 Block 数量相等的 Worker，避免资源浪费（多余的 Worker 会因为队列为空而立即退出）。此规则同时适用于普通查询任务和蒸馏任务。

#### 规则 R3：请求-响应同步

每个工人线程在向远端 AI 发送 Prompt 后（即发送了一个请求后），要等待远端 AI 的回复消息。只有在收到回复的消息之后，才能继续下一轮发送请求。

#### 规则 R4：工人线程的生命周期与任务粒度（采用任务池+抢占模式）

##### a) 任务拆解

当"查询任务分发线程"决定开始执行一个 Query（队首任务）时，它首先将该 Query 拆解为若干个 Block Key（例如 `meta:NATURE:2024`），并将这些 Key 放入该 Query 专属的 Redis List（Key: `task:{uid}:{qid}:pending_blocks`）。

##### b) 线程启动

分发线程根据用户的 permission（例如 2）启动对应数量（2 个）的 Worker 线程。这些 Worker 线程被标记为服务于该 `query_index`。

##### c) 抢占执行

每个 Worker 线程进入一个 `while` 循环：

1. **检查暂停信号**: 读取 Redis `query:{uid}:{qid}:pause_signal`
   - 若存在：将手中已取出的 Block（如果有）推回队列 (`LPUSH`)，然后线程**自动退出销毁**
   - 若不存在：继续下一步

2. **领取任务**: 从 `task:{uid}:{qid}:pending_blocks` 中 `LPOP` 一个 Block Key
   - 如果取到了 Block：执行 R5 规则进行处理
   - 如果 List 为空：说明该 Query 所有 Block 已被领取完毕，Worker 线程自动退出（销毁）

##### d) 设计优势

这种模式下，Worker 自动实现了"续命"，且并发数严格受控于 permission；同时支持快速响应暂停指令，释放系统资源。

#### 规则 R5：工人线程执行的具体流程与数据获取

##### a) 获取数据

Worker 接收到 `Block Key`（如 `meta:NATURE:2024`）后，执行 Redis `HGETALL {Block Key}`，一次性拉取该 Block 下所有文献的 DOI 和**原始 Bib 字符串**（Value 不再是 JSON，而是压缩后的 Bib）。

##### b) 解析与构造

Worker 在内存中解析 Bib 字符串，提取 Title、Abstract 等字段。对于每一篇文献：

1. 构造 Prompt（包含用户问题 + 摘要）
2. 调用 AI API（遵守 R3，同步等待）
3. 获取 `tokens` 消耗，上报给"TPM 累加器"

##### c) 结果写入与原子扣费

收到 AI 判定结果后，Worker 执行以下原子操作（Lua 脚本）：

1. 获取当前 Block 对应刊物的单价 $P$（从 `sys:journals:price`）
2. 检查 `user:{uid}:balance` 是否 >= $P$
3. **若足额**:
   - `DECRBY user:{uid}:balance $P`（实时扣费）
   - `HSET result:{uid}:{query_index} {DOI} {JSON_Result}`（写入结果）
   - `RPUSH billing_queue:{uid} {timestamp, qid, doi, cost: $P}`（写入消费流水）
4. **若余额不足**: 标记该任务失败/跳过，不写入结果也不扣费

##### d) 进度更新

Worker 每处理完一篇，执行 Redis `HINCRBY progress:{uid}:{query_index}:finished_count 1`，用于前端进度条显示。当整个 Block 处理完后，执行 R6 规则进行完成判定。

#### 规则 R6：查询任务完成判定与状态流转

##### a) 初始化

Query 启动时，分发线程计算总 Block 数，写入 `total_blocks` 到 Redis `query:{qid}:status` Hash 中。

##### b) 原子计数

Worker 每处理完一个 Block，执行 `HINCRBY query:{qid}:status finished_blocks 1`。

##### c) 完成判定

Worker 检查 `finished_blocks` 是否等于 `total_blocks`：

- **如果相等**: 该 Worker 负责将 Query 状态标记为 `DONE`，并触发"异步归档"流程（见下文持久化策略），然后销毁
- **如果不等**: 继续循环领取下一个 Block

### 8.3 表 paperinfo 重构

> **重要说明**：MySQL 中应当本就存在表 `paperinfo`。"本就存在"是因为运维人员会手动使用 `DB_tools` 目录下的工具脚本将原始数据转换并存入 MySQL 数据库，而这一步不在也不应该在生产环境的 server 进程中被自动执行。

#### 旧架构设计

在旧架构中，该表用于存储所有的原始文献数据。其中 `Bib` 存放了该条文献的完整 Bib 信息。其余的列，例如 `Name`、`Year`、`Title`、`DOI` 等都是为了旧架构中方便服务进程直接读取指定数据而建的。

#### 新架构设计

新架构中，在查询每一条文献内容的阶段时，不再从 MySQL 查，转而只能从 Redis 查询。所以表 `paperinfo` 应当只保留 Bib 内容，把拆分出来的信息放入 Redis 中的新的存储结构内。

**新架构表结构**: 仅仅保留 2 个列：`DOI` 和 `BIB`。其中 `DOI` 列为主键，其值来自于 BIB 内容（JSON 格式）中的 `doi` 对应的内容。

### 8.4 Block 存储方案

Redis 容器建起后，后台进程运行脚本对 Redis 初始化，将 MySQL 中的表 `paperinfo` 存入 Redis，并本地持久化存储。

基于数据量（500 万篇）和内存（16GB）的评估，以及对查询/下载双重场景的支持，确定采用以下 Block 存储方案：

#### Redis Key 设计

- **类型**: Hash 结构
- **Key**: `meta:<JournalName>:<Year>`（例如 `meta:ANNU REV NEUROSCI:2024`）

#### Field 与 Value

- **Field**: 文献 DOI（例如 `10.1007/s10055...`）
- **Value**: **压缩后的原始 Bib 字符串**

> 不再存储 JSON 对象 `{"t":..., "a":...}`，而是直接存 Bib。因为 Bib 包含了 Title、Abstract、Author、Year 等所有元数据。

#### 设计理由

| 优势 | 说明 |
|-----|------|
| **内存效率** | Bib 格式紧凑，压缩后占用极小。500 万篇约占 8-10GB，完全可加载进内存 |
| **Worker 查询时** | 取出 Bib → 解析出 Abstract → 构造 Prompt → 发送 AI |
| **用户下载时** | 取出 Bib → 直接写入 `.bib` 文件（无需反向转换） |
| **IO 隔离** | 任务只传递 Block Key，Worker 自己去 Redis 取数据，避免了在消息队列中传递大体积文本 |

#### 加载策略

- Redis 启动时，后台脚本从 MySQL `PaperInfo` 表全量加载数据到 Redis
- 设置 TTL（如 7 天），配合 LRU 淘汰冷数据
- Worker 遇到 Key Miss 时回源 MySQL 加载

---

## 9. 任务结果的持久化与下载流程

### 9.1 持久化策略

#### 异步归档

只有当 R6 规则判定 Query 状态变为 `DONE` 时，才启动一个独立的"归档线程"（或复用 Worker 最后一步），将 Redis 中的 `result:{uid}:{qid}` (Hash) 批量写入 MySQL 的 `search_result` 表（新表结构，不再分日期，而是大宽表或分区分表）。

#### MySQL 角色

MySQL 仅作为冷数据备份和审计查询，不参与实时业务，避免 IOPS 瓶颈。

#### Result 缓存 TTL 策略（2025-11-30新增）

| 配置项 | 值 | 说明 |
|--------|-----|------|
| TTL | 7 天 | 防止 Redis 内存无限增长 |
| 稳态内存占用 | ~341MB | 按每日 70,000 篇查询量估算 |
| 回源机制 | 自动 | 蒸馏功能若 Redis MISS（超过 7 天），自动从 MySQL `search_result` 表回源 |
| 回源方法 | `get_relevant_dois_from_mysql(uid, query_id)` | 位于 `lib/load_data/search_dao.py` |

### 9.2 下载任务的消息队列

#### 背景

下载任务是 IO 密集型（读 Redis → 写文件 → 发送），与 CPU/GPU 密集型的 AI 查询任务性质不同。高并发场景下（如 100 个用户同时下载），同步处理会导致线程池耗尽和请求超时。

#### 设计

建立独立的 `download_queue`（Redis List），以及独立的 `DownloadWorker` 线程池（默认 10 个 Worker）。

### 9.3 下载流程详解

| 步骤 | 操作 | 说明 |
|------|------|------|
| a | **用户请求** | 点击"下载CSV"或"下载Bib" → API 创建下载任务 → 立即返回 `task_id` |
| b | **任务入队** | `RPUSH download_queue {task_id, uid, qid, type, timestamp}` |
| c | **前端轮询** | 每秒调用 `GET /api/download/status?task_id=xxx` 查询任务状态 |
| d | **Worker处理** | `DownloadWorker` 从队列 `LPOP` 任务，执行处理流程 |
| e | **文件下载** | 前端检测到状态为 `READY` 后，调用 `GET /api/download/file?task_id=xxx` 获取文件内容 |

#### Worker 处理流程（步骤 d 详解，修复40更新）

1. 更新任务状态为 `PROCESSING`
2. **获取查询结果**（使用 `search_dao.get_all_results()`）:
   - 优先从 Redis `result:{uid}:{qid}` 获取
   - **Redis MISS 时自动回源 MySQL**（修复40）:
     - 查询 `search_result` 表获取 `ai_result`
     - 使用 DOI 反向索引 `idx:doi_to_block` 批量获取 `block_key`
     - 组装完整结果 `{doi: {ai_result, block_key}}`
3. **使用 Redis Pipeline 批量获取**: 收集所有 block_key，一次性获取所有 Bib 数据
4. 在内存中生成 CSV 或 Bib 文件
5. 将文件内容存入 Redis 临时缓存 `download:{task_id}:file`（TTL 5 分钟）
6. 更新任务状态为 `READY`

> **重要（修复40）**: 下载功能支持 MySQL 回源，即使 Redis 数据过期（7天TTL）或被清空，只要任务已归档到 `search_result` 表，历史任务仍可正常下载。

### 9.4 Redis Key 设计

| Key | 类型 | 说明 |
|-----|------|------|
| `download_queue` | List | 全局下载任务队列 |
| `download:{task_id}:status` | Hash | 字段包括 `{state, uid, qid, type, created_at}` |
| `download:{task_id}:file` | String | 生成的文件内容，TTL 5 分钟 |

#### State 状态值

| 状态 | 说明 |
|------|------|
| `PENDING` | 待处理 |
| `PROCESSING` | 处理中 |
| `READY` | 已就绪 |
| `FAILED` | 失败 |

### 9.5 性能优化：批量获取

#### 核心优化

使用 Redis Pipeline 批量获取 Block 数据，将 O(n) 次网络往返优化为 O(1) 次。

#### 实现方式

Worker 先遍历所有结果收集 block_key 列表，然后使用 Pipeline 执行批量 HGETALL，最后组装结果。

#### 性能对比（1000篇文献，每次Redis往返10ms）

| 方式 | 耗时 |
|------|------|
| 逐个获取 | 1000 × 10ms = 10秒 |
| Pipeline批量获取 | 1次 × 50ms ≈ 50毫秒 |

### 9.6 高并发场景分析

#### DownloadWorker 池配置

默认 10 个 Worker。

#### 100用户并发下载场景（每人1000篇）

| 指标 | 数值 |
|------|------|
| 请求响应 | 立即返回 task_id（<100ms） |
| 平均等待 | (100/10) × 2秒 / 2 = 10秒 |
| 最长等待 | (100/10) × 2秒 = 20秒 |

#### 设计优势

- **用户请求不阻塞**: 立即返回任务 ID，不占用 Web Server 线程
- **并发控制**: Worker 池限制最大并发，保护 Redis IOPS 和网络带宽
- **资源隔离**: 下载任务与查询/蒸馏任务使用独立的 Worker 池

### 9.7 API 接口设计

#### 创建下载任务

```
POST /api/download/create
```

- **请求**: `{query_id, type: "csv"|"bib"}`
- **响应**: `{success: true, task_id: "..."}`

#### 查询任务状态

```
GET /api/download/status?task_id=xxx
```

- **响应**: `{state: "PENDING"|"PROCESSING"|"READY"|"FAILED", progress: 0-100}`

#### 下载文件

```
GET /api/download/file?task_id=xxx
```

- **响应**: 文件内容（Content-Disposition 头）

> **废弃旧 API（修复36）**: 已删除 `/api/download_csv` 和 `/api/download_bib` 旧架构同步下载 API，统一使用异步下载机制。

---

## 9.5 API 请求 Token 认证规范（修复37新增）

为了解决原有架构中前端可随意伪造 uid 调用任意 API 的严重安全漏洞，新架构实现了完整的 Token 认证机制：

### Token 格式

```
Authorization: Bearer {token}
```

- Token 通过 HTTP 请求头传递
- Token 为 64 字符的安全随机字符串

### 认证流程

1. 后端从请求头的 Authorization 字段提取 Token
2. 查询 Redis `user:session:{token}` 获取 uid
3. uid 存在且 Token 未过期则认证通过，继续处理业务逻辑
4. uid 不存在或 Token 过期则返回 401 Unauthorized
5. 认证通过后刷新 Token 的 TTL（访问延期）

### 受保护端点

除以下公开端点外，所有 `/api/*` 端点都需要 Token 认证：

| 端点 | 说明 |
|------|------|
| `/api/login`, `/api/register` | 用户登录注册 |
| `/api/tags`, `/api/journals`, `/api/count_papers` | 公开数据查询 |
| `/api/registration_status` | 注册开关状态 |
| `/api/system_announcement` | 公告栏内容 |
| `/api/maintenance_status` | 维护模式状态 |

### Redis Key 设计

- **Key**: `user:session:{token}` (String)
- **Value**: uid (用户ID)
- **TTL**: 24小时（每次访问刷新）

### 前端实现

- 登录成功后将 token 存入 localStorage
- 封装 `authFetch(url, options)` 辅助函数自动添加 Authorization 头
- 401 响应时自动跳转登录页

### 文件下载特殊处理

浏览器跳转下载无法设置 header，因此 `/api/download/file` 支持 URL 参数传递 Token：

```
?task_id=xxx&token=xxx
```

---

## 9.6 公告栏与维护模式（修复35新增）

### 公告栏功能

1. 管理员在 `/admin/control.html` 开启公告栏并设置内容
2. 用户页面（`login.html`, `index.html`）加载时调用 `/api/system_announcement`
3. 公告内容显示在页面顶部横幅中
4. 支持中英文切换

### 维护模式功能

1. 管理员开启维护模式后，用户页面检测到会跳转到 `/maintenance.html`
2. 维护页面显示维护公告内容（支持自定义）
3. 管理员页面不受维护模式影响
4. 维护模式下所有用户 API 请求被拦截

### 系统配置项

存储在 MySQL `system_settings` 表和 Redis `sys:config:*` 中：

| 配置项 | 默认值 | 说明 |
|--------|--------|------|
| `announcement_enabled` | false | 公告栏开关 |
| `announcement_content` | 空 | 公告内容 |
| `maintenance_mode` | false | 维护模式开关 |
| `maintenance_message` | 中英文双语提示 | 维护公告内容 |

### API 接口

| 端点 | 响应 |
|------|------|
| `GET /api/system_announcement` | `{enabled: bool, content: string}` |
| `GET /api/maintenance_status` | `{maintenance_mode: bool, message: string}` |

### 检查时机

- 用户页面加载时主动检查维护模式状态
- 若处于维护模式，前端 JavaScript 自动重定向到 `/maintenance.html`

---

## 10. 安全与多用户隔离设计（安全修正案）

为了防止多用户环境下的数据串扰（如用户 B 下载用户 A 的结果），必须强制执行以下隔离规范：

### 10.1 Redis Key 命名空间隔离

#### 核心原则

- **严禁**使用全局 ID 作为 Key 的唯一标识
- 所有与用户数据相关的 Key 必须前缀 `{uid}`

#### 修正后的 Key 规范

| 用途 | 修正后格式 | 原格式 |
|------|-----------|--------|
| 任务状态 | `query:{uid}:{qid}:status` | `query:{qid}:status` |
| 结果存储 | `result:{uid}:{qid}` | `result:query:{qid}` |
| 任务队列 | `task:{uid}:{qid}:pending_blocks` | `task:query:{qid}:...` |
| 进度条 | `progress:{uid}:{qid}:finished_count` | `progress:query:{qid}:...` |

### 10.2 下载权限强校验

#### API 层校验

在将下载请求放入 `download_queue` 之前，API 层必须校验：当前登录用户的 `session.uid` 是否等于请求参数中的 `uid`。

#### Worker 层校验

`DownloadWorker` 从队列取出任务（包含 `uid` 和 `qid`）后，在读取 Redis 数据时，必须拼接 `{uid}` 前缀（例如读取 `result:{uid}:{qid}`）。

#### 安全效果

即使恶意用户 B 猜到了 A 的 `qid`，但他构造的下载请求要么被 API 层拦截（uid 不匹配），要么在 Worker 层因为 Key 拼接了 B 的 uid 而读不到数据（Redis 中不存在 `result:B:{qid_of_A}`），从而**物理上杜绝了越权访问**。

---

## 11. 高效余额扣费与持久化设计（Billing System）

为了平衡"高性能扣费"与"资金安全"，采用 **Redis 实时扣费 + 异步流水对账** 模式：

### 11.1 数据准备

在步骤 5（加载 ContentList 到 Redis）时，必须同步加载 `price` 信息。

#### 数据结构

- **Key**: `sys:journals:price` (Hash)
- **Field**: 期刊名（如 `ANNU REV NEUROSCI`）
- **Value**: 价格（如 `2`）

### 11.2 消费流水队列

#### Redis Key

`billing_queue:{uid}` (List)

#### 作用

记录每一次成功的扣费操作，作为 Write-Ahead Log (WAL)。即使 Redis 发生故障，只要 AOF 开启，流水记录就不会丢失，可用于重建余额或审计。

### 11.3 后台对账线程（BillingSyncer）

#### 职责

负责将 Redis 中的消费流水批量同步到 MySQL，确保数据库余额最终一致。

#### 处理流程

1. 循环扫描所有活跃用户的 `billing_queue:{uid}`
2. 取出一批流水记录（例如 100 条），计算总扣费金额 `total_deduct`
3. 执行 MySQL 事务：`UPDATE user_info SET balance = balance - total_deduct WHERE uid = ...`
4. 只有当 MySQL 更新成功后，才从 Redis Queue 中截断（Trim）已同步的记录

#### 设计优势

MySQL 承受的是聚合后的低频更新（如每秒 1 次），而不是 Worker 产生的高频更新（如每秒 1000 次），极大保护了数据库性能。

---

## 12. 废弃功能与变更说明

### 废弃"删除历史记录"功能

**决策**: 新架构彻底移除 `delete_query` / `hide_query` 相关接口与逻辑。

#### 废弃理由

| 理由 | 说明 |
|------|------|
| **审计合规** | 防止用户通过删除记录规避扣费审计 |
| **架构简化** | 减少 Redis/MySQL 中维护 `is_visible` 状态的复杂度 |
| **数据完整性** | 保证所有 `query_log` 和 `billing_log` 永久可追溯 |

---

## 13. 任务暂停与恢复设计

在旧架构中，暂停是通过修改 MySQL `query_log.should_pause` 字段实现的。新架构中，采用基于 Redis Key 的"信号灯"机制：

### 13.1 信号灯设计

- **Key**: `query:{uid}:{qid}:pause_signal` (String, Value="1")
- **语义**: 存在即表示"暂停中"，不存在即表示"正常运行"

### 13.2 暂停流程

1. 用户点击"暂停" → API 设置 `pause_signal`
2. **Worker 响应**（修正 R4 规则）：
   - Worker 在 `LPOP` Block 之前，先检查 `pause_signal` 是否存在
   - **若存在**：
     1. 将该 Worker 手中已取出但尚未开始处理的 Block（如果有）推回队列头部 (`LPUSH`)
     2. Worker 线程直接**结束运行并销毁**
   - **结果**: 该任务占用的 CPU/内存资源被完全释放，仅保留 Redis 队列中的待处理 Block

### 13.3 恢复流程

1. 用户点击"继续" → API 删除 `pause_signal` → API 重新调用"分发器"逻辑
2. 分发器检测到该 Query 还有 `pending_blocks`，根据 permission 重新生产新的 Worker 线程继续消费

### 13.4 僵尸任务处理

为防止用户暂停后永远不恢复，可为 `pause_signal` 设置 TTL（如 7 天）。过期后，配合定期清理脚本将长期未动的任务标记为"已终止"并清理队列。

---

## 13.5 任务终止（Terminate）设计

区别于"暂停"的软性停止，"终止"是强制且不可恢复的操作：

### 信号设计

- **Key**: `query:{uid}:{qid}:terminate_signal` (String, Value="1", TTL 7天)
- **优先级**: 高于 `pause_signal`

### 终止流程

1. 用户/管理员点击"终止" → API 设置 `terminate_signal`
2. API 将任务状态设为 `CANCELLED` 并清空 `pending_blocks` 队列
3. API 调用 `stop_workers_for_query` 向所有活跃 Worker 发送信号

### Worker 响应

1. Worker 循环中检测到 `terminate_signal`
2. 立即停止当前处理，**不**将手中的 Block 推回队列
3. 打印"收到终止信号"日志并退出销毁

---

## 14. 蒸馏任务业务全流程设计

蒸馏任务本质上是一个"输入范围受限"的查询任务。它复用大部分查询架构，但在数据源和计费上有所不同。

### 14.1 数据源与复用

#### 范围对比

| 任务类型 | 数据范围 |
|---------|---------|
| 普通查询 | 用户选择的刊物 × 年份（Blocks） |
| 蒸馏查询 | 上一次任务（父任务）中判定为"相关"的文献集合 |

#### 复用策略

利用 Redis `result:{uid}:{parent_qid}` Hash 中存储的 `JSON_Result`（或隐含的 DOI），以及 Redis Block 中存储的原始 Bib。

#### 数据获取修正

由于 `result` Hash 中只存了 AI 结果 JSON，Worker 蒸馏时仍需获取 Bib/Abstract。

**推荐方案**: `result:{uid}:{qid}` 的 Value 结构升级为：

```json
{"ai_result": ..., "block_key": "meta:..."}
```

这样蒸馏时，Worker 拿到 DOI 后可直接获取 BlockKey，再从 Block Hash 中读取 Bib。

### 14.2 蒸馏任务队列

复用 `task:{uid}:{qid}:pending_blocks` 结构，但其中的"Block"不再是刊物年份 Key，而是**临时生成的 DOI 分片（Distill Chunk）**。

#### Redis Key 格式

- **Key**: `distill_chunk:{uid}:{qid}:{chunk_id}` (List)
- **内容**: 存储本批次待蒸馏的 DOI 列表

> **API 参数修正**: 发起蒸馏时，必须使用 `original_query_id` (String) 而非 `query_index` (Int)，因为新架构 Query ID 为字符串格式。

### 14.3 流程设计

#### A. 估算阶段

1. 读取 `result:{uid}:{parent_qid}` 中所有 `search_result=1` 的 DOI
2. 统计数量 $N$
3. 估算费用 $Cost = N \times Price \times 0.1$

#### B. 提交阶段

1. 创建新 `query_log`（`is_distillation=1`）
2. 将 $N$ 个 DOI 按每 100 个分片，存入 `distill_chunk:{uid}:{qid}:{chunk_id}`
3. 将 Chunk Key 推入 `task:{uid}:{qid}:pending_blocks`
4. 启动分发器（Worker数量同样遵循规则R2补充：实际启动Worker数 = `min(permission, Chunk数量)`）

#### C. Worker 执行阶段

1. Worker 识别任务类型（Distillation，通过 Key 前缀或 metadata）
2. `LPOP` 一个 `distill_chunk` Key
3. 遍历 Chunk 中的 DOI：
   - 从 `result:{uid}:{parent_qid}` 获取该 DOI 的 `block_key`
   - 从 `meta:{block_key}` 获取 Bib/Abstract
   - 执行 AI 判断
4. **扣费**: 应用蒸馏费率（从 `sys:config:distill_rate` 动态获取，默认 0.1），流程同 Billing System

### 14.4 蒸馏专用 Block 设计（修复29-31新增）

#### 问题背景

原设计使用 `meta:` 格式完整 Block，导致 Worker 处理整个 Block 中的所有论文，而非仅相关 DOI。

#### 解决方案

创建 `distill:{uid}:{qid}:{index}` 格式的蒸馏专用 Block。

#### Redis Key 格式

- **Key**: `distill:{uid}:{qid}:{block_index}` (Hash, TTL 7天)
- **Field**: DOI
- **Value**: JSON `{"bib": "原始Bib字符串", "price": 期刊单价}`

#### 设计优势

- Worker 从 Block 直接读取价格，0 次额外 Redis 查询
- 精确控制处理范围
- 每个 Block 最多 100 个 DOI

### 14.5 蒸馏费率传递优化（IOPS优化版）

#### 优化流程

1. 预估阶段计算 `doi_prices` 字典（DOI → 价格映射），返回三元组 `(dois, cost, doi_prices)`
2. `_handle_start_distillation` 传递 `doi_prices` 给 `process_papers_for_distillation`
3. `distillation_producer` 将价格信息嵌入 Block 的 Value 中
4. `DistillWorker.__init__` 初始化时缓存蒸馏费率（1次 Redis 调用）
5. Worker 处理时从 Block 解析价格（0次额外调用）

#### IOPS 效果统计

| 阶段 | Redis 调用次数 |
|------|---------------|
| 预估阶段 | 3次（与文献数量N无关） |
| Worker阶段 | 0次额外Redis调用 |
| 蒸馏费率 | 1次（初始化时缓存） |

### 14.6 DOI 反向索引（修复26新增）

#### 问题背景

蒸馏时需要根据 DOI 查找对应的 block_key，原实现遍历所有 Block，复杂度 O(n*m)。

#### 解决方案

新增 DOI 反向索引：

- **Redis Key**: `idx:doi_to_block` (Hash)
- **Field**: DOI
- **Value**: block_key（如 `meta:NATURE:2024`）

#### 构建时机

Redis 初始化时自动构建（阶段 3.5）。

#### 查询方法

| 方法 | 说明 |
|------|------|
| `PaperBlocks.get_block_key_by_doi(doi)` | O(1) 单个查询 |
| `PaperBlocks.batch_get_block_keys(dois)` | Pipeline 批量获取 |

---

## 15. 部署架构与网络拓扑

### 15.1 网络架构

| 组件 | 说明 |
|------|------|
| **DNS** | 阿里云解析 → ECS 公网 IP |
| **ECS** | 承载所有服务组件 |

#### ECS 内部组件

| 组件 | 说明 |
|------|------|
| **Nginx** | 80/443 端口，负责静态文件服务、SSL 终止、API 反向代理 |
| **Backend** | Docker 容器，运行 Python 业务进程 |
| **Redis** | Docker 容器，仅监听 127.0.0.1，不暴露公网 |
| **RDS MySQL** | 通过 VPC 内网连接，不暴露公网 |

### 15.2 安全组策略

#### ECS 安全组开放端口

| 端口 | 协议 | 说明 |
|------|------|------|
| 80 | HTTP | Web 访问 |
| 443 | HTTPS | 加密 Web 访问 |
| 22 | SSH | 远程管理 |

#### 屏蔽的端口

| 端口 | 说明 |
|------|------|
| 6379 | Redis（禁止公网访问） |
| 3306 | MySQL（禁止公网访问） |

### 15.3 负载均衡

当前阶段不使用 SLB，直接通过 ECS 公网 IP 访问。SSL 证书部署在 ECS 的 Nginx 上。

---

## 16. 新版管理员系统设计

### 16.1 账户隔离策略

#### MySQL 层面

新增 `admin_info` 表，结构：

| 字段 | 说明 |
|------|------|
| uid | 管理员 ID |
| username | 用户名 |
| password | 密码（bcrypt 哈希） |
| role | 角色 |
| created_at | 创建时间 |

物理隔离于 `user_info` 表。

#### Redis 层面

- 会话存储: `admin:session:{token}`
- 热点数据: `admin:{uid}:info`

### 16.2 访问控制

#### 独立登录

- 新增 `/admin/login.html`
- 调用 `/api/admin/login`

#### 中间件鉴权

后端中间件严格区分：

| 路径前缀 | 验证方式 |
|---------|---------|
| `/api/admin/*` | 查 admin session |
| `/api/*` | 查 user session |

### 16.3 功能模块设计

#### 用户管理

- 列表展示
- 余额充值/扣除
- 权限调整
- 账号封禁

#### 管理员管理

超级管理员可增删普通管理员。

#### 系统监控大盘

| 监控项 | 数据来源 |
|--------|---------|
| **任务监控** | 实时 TPM/RPM（滑动窗口）、Redis 队列积压数、活跃 Worker 数 |
| **健康监控** | Redis/MySQL 连接状态、Billing Queue 积压报警 |

#### 系统控制

新增 `control.html` 页面，提供以下全局配置的实时切换：

| 功能 | API |
|------|-----|
| 用户注册开关 | `/api/admin/toggle_registration` |
| 公告栏管理 | 开关和内容设置 |
| 维护模式管理 | 开关和维护公告内容 |

### 16.4 批量操作 API（修复32新增）

#### 批量调整余额

```
POST /api/admin/users/batch_balance
```

- **请求**: `{items: [{uid}], operation: "increase"|"decrease"|"set", amount: number}`
- **响应**: `{success: true, message: "...", success_count: N}`

#### 批量调整权限

```
POST /api/admin/users/batch_permission
```

- **请求**: `{items: [{uid}], permission: number}`
- **响应**: `{success: true, message: "...", success_count: N}`

#### 批量终止任务

```
POST /api/admin/tasks/batch_terminate
```

- **请求**: `{items: [{uid, query_id}]}`
- **响应**: `{success: true, message: "...", success_count: N, workers_stopped: M}`

#### 批量暂停/恢复任务

```
POST /api/admin/tasks/batch_pause
POST /api/admin/tasks/batch_resume
```

### 16.5 DataTable 组件（修复32新增）

管理员页面（dashboard/users/tasks）使用可复用 DataTable 组件：

| 功能 | 说明 |
|------|------|
| 分页 | 支持页码切换 |
| 排序 | 支持列排序 |
| 搜索 | 支持关键字搜索 |
| 筛选 | 支持条件筛选 |
| 全选/勾选 | 支持批量选择 |
| 批量操作 | 支持批量执行 |
| Toast 提示 | 操作成功后使用 Toast 提示替代 alert 弹窗 |

### 16.6 刷新控制功能（修复33新增）

dashboard/users/tasks 页面支持：

| 功能 | 说明 |
|------|------|
| 立即刷新 | 手动触发刷新 |
| 暂停/继续 | 暂停或继续自动刷新 |
| 刷新间隔选择 | 1/2/5/10/30 秒可选 |

### 16.7 废弃项

- 删除 `AutoPaperSearchControlPanelAdmin.html`
- 移除所有未经过鉴权的旧版管理接口

---

## 17. DB_tools 重构与数据库初始化流程

在新架构中，`DB_tools` 目录将从"手动辅助工具集"转变为"标准化数据库初始化套件"。旧有的多个分散脚本将被整合并重写，以支持自动建表、数据导入、数据清洗和统计。

### 17.1 废弃说明

以下旧组件和概念将被彻底废弃：

| 废弃项 | 说明 |
|--------|------|
| **表 `sentence`** | 彻底移除。新架构直接在 Redis Block 中存储完整 Bib，Worker 内存解析 Abstract，无需再拆解为句子存储 |
| **表 `api_usage_minute`** | 彻底移除。流控统计改为内存滑动窗口（TPM/RPM） |
| **表 `app_settings`** | 彻底移除。静态配置走 `config.json`，动态业务数据走 Redis |
| **表 `task_queue`** | 彻底移除。任务队列完全由 Redis List 接管 |
| **脚本 `tools_refresh_db_sentence.py`** | 废弃 |
| **README.md 中的手动 SQL 建表命令** | 废弃。所有建表操作将由 Python 脚本自动完成 |

### 17.2 新工具设计：init_database.py

我们将创建一个统一入口脚本 `init_database.py`，它负责按正确顺序调用内部模块完成数据库初始化。

#### 目录结构

```
DB_tools/
├── init_database.py        # 主入口脚本
├── config.json             # 数据库连接配置
├── requirements.txt        # 依赖包 (mysql-connector-python, bibtexparser)
├── lib/                    # 内部模块库
│   ├── db_schema.py        # 定义所有 CREATE TABLE SQL
│   ├── loader_bib.py       # Bib文件解析与导入 (ContentList, PaperInfo, YearNumber)
│   ├── loader_tags.py      # 标签与映射导入 (InfoTag, InfoPaperWithTag)
│   └── loader_api.py       # API Key 导入 (ApiList)
├── Data/                   # 存放 .bib 原始数据的文件夹 (按期刊名命名)
├── PaperAndTagInfo/        # 存放 CSV 元数据 (InfoList.Paper.csv 等)
└── APIKey/                 # 存放 API Key 文本文件
```

### 17.3 数据库初始化流程

运维人员只需配置好 `config.json` 并放入数据文件，然后运行 `python init_database.py`。脚本将自动执行以下步骤：

#### Step 1: 基础表结构创建（db_schema.py）

1. 连接 MySQL，设置会话字符集为 `utf8mb4`
2. 自动创建以下表（若不存在）：

| 表名 | 说明 |
|------|------|
| `user_info` | 用户表 (uid, username, password, balance, permission) |
| `admin_info` | 管理员表 (uid, username, password, role) |
| `api_list` | API 密钥表 (api_key, limit) |
| `contentlist` | 期刊元数据表 (Name, FullName, DataRange, Price) |
| `contentlist_year_number` | **[新增]** 年份统计表 (Name, YearNumberJson) |
| `paperinfo` | **[重构]** 文献表 (DOI, Bib) —— *极大精简，仅存 Bib JSON* |
| `info_tag` | 标签表 (Tag, TagType) |
| `info_paper_with_tag` | 映射表 (Name, Tag) |
| `query_log` | 任务记录表（归档用） |
| `search_result` | 结果记录表（归档用） |

#### Step 2: API Key 导入（loader_api.py）

扫描 `APIKey/` 目录，去重导入 `api_list` 表。

#### Step 3: 期刊与文献导入（loader_bib.py）

1. 读取 `PaperAndTagInfo/InfoList.Paper.csv`，更新 `contentlist` 表的基础信息
2. 遍历 `Data/` 目录下的子文件夹（期刊名）：
   - 解析每个 `.bib` 文件
   - **构建 PaperInfo**: 提取 DOI 和完整 Bib 字符串，封装为 JSON (`{"bib": "..."}`) 存入 `paperinfo` 表
   - **统计年份数据**: 在内存中累计该期刊每个年份的文献数量
   - **写入统计**: 将统计结果（如 `{"2023": 150, "2024": 200}`）序列化为 JSON，写入 `contentlist_year_number` 表

> **注意**: 不再拆解 Title/Author/Abstract 为独立列，全部压入 Bib 字段。鉴于 MySQL 性能，建议 `PaperInfo` 表结构为 `DOI VARCHAR(255) PK, Bib JSON`。

#### Step 4: 标签导入（loader_tags.py）

1. 读取 `InfoList.Tag.csv`，全量同步 `info_tag` 表
2. 读取 `InfoList.PaperWithTag.csv`，导入 `info_paper_with_tag` 表

### 17.4 关键表 SQL 定义

> **注：以下 SQL 定义包含修复35新增的 `system_settings` 表**

#### 1. 用户表

```sql
CREATE TABLE IF NOT EXISTS user_info (
    uid INT AUTO_INCREMENT PRIMARY KEY,
    username VARCHAR(255) NOT NULL UNIQUE,
    password VARCHAR(255) NOT NULL,
    balance DECIMAL(10, 2) DEFAULT 0.00,
    permission INT DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
```

#### 2. 管理员表

```sql
CREATE TABLE IF NOT EXISTS admin_info (
    uid INT AUTO_INCREMENT PRIMARY KEY,
    username VARCHAR(255) NOT NULL UNIQUE,
    password VARCHAR(255) NOT NULL,
    role VARCHAR(50) DEFAULT 'admin',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
```

#### 3. 期刊列表

```sql
CREATE TABLE IF NOT EXISTS contentlist (
    Name VARCHAR(255) PRIMARY KEY,
    FullName TEXT,
    DataRange TEXT,
    UpdateDate TEXT,
    Price INT DEFAULT 1
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
```

#### 4. 期刊年份统计（新增）

```sql
CREATE TABLE IF NOT EXISTS contentlist_year_number (
    Name VARCHAR(255) PRIMARY KEY,
    YearNumberJson JSON COMMENT '格式: {"2023": 100, "2024": 50}'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
```

#### 5. 文献表（重构）

```sql
CREATE TABLE IF NOT EXISTS paperinfo (
    DOI VARCHAR(255) PRIMARY KEY,
    Bib JSON NOT NULL COMMENT '包含完整 BibTex 字符串及元数据'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
```

#### 6. 标签表

```sql
CREATE TABLE IF NOT EXISTS info_tag (
    Tag VARCHAR(255) PRIMARY KEY,
    TagType VARCHAR(255) NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
```

#### 7. 标签映射表

```sql
CREATE TABLE IF NOT EXISTS info_paper_with_tag (
    id INT AUTO_INCREMENT PRIMARY KEY,
    Name VARCHAR(255) NOT NULL,
    Tag VARCHAR(255) NOT NULL,
    UNIQUE KEY uniq_name_tag (Name, Tag),
    INDEX idx_tag (Tag)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
```

#### 8. 任务日志（归档）

```sql
CREATE TABLE IF NOT EXISTS query_log (
    query_id VARCHAR(64) PRIMARY KEY,
    uid INT NOT NULL,
    search_params JSON,
    start_time DATETIME,
    end_time DATETIME,
    status VARCHAR(50),
    total_cost DECIMAL(10, 2),
    INDEX idx_uid (uid)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
```

#### 9. 搜索结果（归档）

```sql
CREATE TABLE IF NOT EXISTS search_result (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    uid INT NOT NULL,
    query_id VARCHAR(64) NOT NULL,
    doi VARCHAR(255) NOT NULL,
    ai_result JSON,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_query (query_id),
    INDEX idx_uid (uid)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
```

#### 10. API 列表

```sql
CREATE TABLE IF NOT EXISTS api_list (
    api_index INT AUTO_INCREMENT PRIMARY KEY,
    api_key VARCHAR(512) NOT NULL UNIQUE,
    api_name VARCHAR(255),
    rpm_limit INT DEFAULT 3000,
    tpm_limit BIGINT DEFAULT 500000,
    is_active TINYINT(1) DEFAULT 1
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
```

#### 11. 系统配置表（修复17/35新增）

```sql
CREATE TABLE IF NOT EXISTS system_settings (
    setting_key VARCHAR(100) PRIMARY KEY,
    setting_value TEXT,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
```

#### 系统配置默认值

| 配置项 | 默认值 | 说明 |
|--------|--------|------|
| `permission_min` | 0 | 权限最小值 |
| `permission_max` | 10 | 权限最大值 |
| `distill_rate` | 0.1 | 蒸馏费率系数 |
| `registration_enabled` | true | 用户注册开关 |
| `debug_console_enabled` | false | 调试日志开关 |
| `announcement_enabled` | false | 公告栏开关 |
| `announcement_content` | "" | 公告内容 |
| `maintenance_mode` | false | 维护模式开关 |
| `maintenance_message` | "系统维护中..." | 维护公告 |

### 17.5 AI 语言适配机制（修复36新增）

为了让 AI 的回复语言与用户界面语言保持一致，新架构实现了语言适配机制：

#### 数据流

1. 前端 `startSearch`/`startDistillation` 传递 `language: i18n.getLang()` (`'zh'`/`'en'`)
2. 后端存入 `search_params.language`
3. Worker 读取 `search_params.language`，替换 `system_prompt` 中的 `{language}` 占位符

#### 语言映射

位于 `lib/process/search_paper.py`：

| 代码 | 映射值 |
|------|--------|
| `zh` | `中文` |
| `en` | `English` |

#### CSV 下载优化

| 优化项 | 说明 |
|--------|------|
| **排序** | 按相关性排序：相关(Y)在前，不相关(N)在后 |
| **Is_Relevant 列本地化** | zh 模式: "符合" / "不符"；en 模式: "Relevant" / "Irrelevant" |

#### BIB 文件

不包含任何头信息注释，直接输出 BIB 条目。

#### config.json 中的 system_prompt 配置

包含 `{language}` 占位符：

```json
"system_prompt": "请用{language}回复。分析以下摘要..."
```

### 17.6 Redis Key 完整汇总（修复24-40更新）

以下是新架构中所有 Redis Key 的完整列表：

#### 用户数据

| Key 格式 | 类型 | TTL | 说明 |
|---------|------|-----|------|
| `user:{uid}:info` | Hash | 8h | 用户基本信息 |
| `user:{uid}:balance` | String | 8h | 用户余额 |
| `user:{uid}:history` | ZSet | - | 查询历史 |
| `user:session:{token}` | String | 24h | 用户登录会话 Token（修复37） |

#### 管理员数据

| Key 格式 | 类型 | TTL | 说明 |
|---------|------|-----|------|
| `admin:session:{token}` | String | 24h | 管理员会话 |
| `admin:{uid}:info` | Hash | 8h | 管理员缓存 |

#### 系统元数据（永不过期）

| Key 格式 | 类型 | 说明 |
|---------|------|------|
| `sys:tags:info` | Hash | 标签元数据 |
| `sys:tag_journals:{Tag}` | Set | 标签-期刊索引 |
| `sys:journals:info` | Hash | 期刊信息 |
| `sys:journals:price` | Hash | 期刊价格 |
| `sys:year_number:{Name}` | String | 年份统计 |
| `sys:config:{key}` | String | 系统配置缓存 |

#### 文献数据（永不过期）

| Key 格式 | 类型 | 说明 |
|---------|------|------|
| `meta:{JournalName}:{Year}` | Hash | 文献 Block |
| `idx:doi_to_block` | Hash | DOI 反向索引（修复26） |

#### 任务与队列

| Key 格式 | 类型 | TTL | 说明 |
|---------|------|-----|------|
| `task:{uid}:{qid}:pending_blocks` | List | - | 待处理 Block 队列 |
| `query:{uid}:{qid}:status` | Hash | - | 任务状态 |
| `query:{uid}:{qid}:pause_signal` | String | - | 暂停信号 |
| `query:{uid}:{qid}:terminate_signal` | String | 7天 | 终止信号 |
| `progress:{uid}:{qid}:finished_count` | String | - | 进度计数 |
| `result:{uid}:{qid}` | Hash | 7天 | 查询结果缓存（过期后蒸馏/下载回源MySQL，修复40） |

#### 蒸馏专用（修复29）

| Key 格式 | 类型 | TTL | 说明 |
|---------|------|-----|------|
| `distill:{uid}:{qid}:{index}` | Hash | 7天 | 蒸馏专用 Block |

#### 计费

| Key 格式 | 类型 | 说明 |
|---------|------|------|
| `billing_queue:{uid}` | List | 消费流水队列 |

#### 下载队列

| Key 格式 | 类型 | TTL | 说明 |
|---------|------|-----|------|
| `download_queue` | List | - | 全局下载任务队列 |
| `download:{task_id}:status` | Hash | - | 下载任务状态 |
| `download:{task_id}:file` | String | 5min | 下载文件内容 |

---

**文档结束**


