我现在要做的事情：
1）按照新架构的业务流程想象，依次重构MySQL数据库的各个表，确保仅MySQL中存放更新频率低、体积大的数据。
2）设计Redis内数据存放的方式。以16G缓存为上限。所有需要被频繁调取的数据必须放在Redis中。
3）注：MySQL使用编码：utf8mb4，排序方式：utf8mb4_0900_ai_ci
现在我正在本文档中一点点地撰写新架构下MySQL和Redis各自的数据存储方式，以下是我正在写的重构构思的正文部分（按照新架构的业务流程进行）。
===1. 用户注册和登录===
用户注册和登录的server进程首先访问Redis中与MySQL的表user_info相关的数据，如果在Redis中没有找到，则直接访问MySQL进行读写，奉行“缓存未命中则回源 MySQL 加载”的策略（Lazy Loading）。在从MySQL加载后，要把数据同时写入Redis，写入 Redis 时设置一个较长的过期时间（TTL，如8小时），表user_info相关的数据过期之前必须先按照以下规则同步写回MySQL：
Redis数据过期前写回MySQL的策略：a）可被写回的数据：balance。b）不可写回的数据：其他所有数据。c）只有确认了数据被成功写回MySQL后，Redis中的对应数据才能成功被过期删除，否则多次尝试写回（条件C仅对“过期删除”策略有效）。
Redis还未过期的数据写回MySQL的策略：a）可被写回的数据：balance。b）不可写回的数据：其他所有数据。c）写回的时机：该数据每次被改变（更新）之后立即写回MySQL。
Redis中，表user_info相关的“未过期的”数据必须本地持久化，未过期期间其本地持久化的数据不能被删除，但过期后一定要删除。
（需要在config中加一个开关，以在本地开发者模式开启时（"local_develop_mode": true），可以调试开启或关闭“表user_info相关的“未过期的”数据”的本地持久化功能（加载不同的docker-compose.local.yml））。
关于表user_info：
1）首先，MySQL中应当本就存在表user_info。“本就存在”这两个表是因为运维人员会手动使用DB_tools目录下的工具脚本将原始数据转换并存入MySQL数据库，而这一步不在也不应该在生产环境的server进程中被自动执行。
表user_info的具体信息如下：
+------------+---------------+------+-----+---------+----------------+
| Field      | Type          | Null | Key | Default | Extra          |
+------------+---------------+------+-----+---------+----------------+
| uid        | int           | NO   | PRI | NULL    | auto_increment |
| username   | varchar(255)  | NO   | UNI | NULL    |                |
| password   | varchar(255)  | NO   |     | NULL    |                |
| balance    | decimal(10,2) | YES  |     | 0.00    |                |
| permission | int           | YES  |     | 0       |                |
+------------+---------------+------+-----+---------+----------------+
uid: 用户唯一 ID (Primary Key, 自增)。
username: 用户登录名 (Unique)。
password: 用户密码 (存储为 bcrypt 哈希值)。
balance: 账户余额 (用于支付检索费用)。
permission: 用户并发权限 (允许同时使用的最大线程数)。
内容示例：
mysql> select * from user_info limit 1;
+-----+----------+--------------------------------------------------------------+----------+------------+
| uid | username | password                                                     | balance  | permission |
+-----+----------+--------------------------------------------------------------+----------+------------+
|   1 | asher    | $2b$12$MbT8lgcjHO5Rx4HlHODxAekNQLyXDDuSp9sQp3A574rU4/M0d4d8q | 90076.00 |        2 |
+-----+----------+--------------------------------------------------------------+----------+------------+
2）Redis中与MySQL的表user_info相关的数据的存储方式：
- **UserInfo Hash**: `user:{uid}:info` (存储 username, permission 等，TTL 8小时，访问延期)。
- **Balance String/Hash**: `user:{uid}:balance` (存储当前余额，独立 Key 以支持高频原子操作，TTL 8小时)。
- **策略**: 读操作优先查 Redis，MISS 则回源 MySQL 并写入 Redis。写操作（如充值）先更新 MySQL 再更新/删除 Redis。扣费操作（高频）走 Billing System（见第11章）。
===2. 用户登录后，主页刷新历史记录===
1）**Redis Key**: `user:{uid}:history` (ZSet, Score=Timestamp, Member=query_index)。
2）**存储内容**: 仅存储 `query_index` 的列表。
3）**加载策略**:
- 优先 `ZREVRANGE user:{uid}:history 0 10` 获取最近的任务 ID。
- 拿着 ID 去查 `query_log` 表（或 Redis 中的 `query:{uid}:{qid}:info` 缓存）。
- 若 Redis History 为空，回源 MySQL `list_query_logs_by_uid` 并重建缓存。
===3. 获取导航栏显示的用户余额===
如果前面的步骤“1. 用户注册和登录”已经成功进行，那进行到现在的步骤3时，Redis中已经存在了与MySQL的表user_info相关的数据。
所以仿照步骤“1. 用户注册和登录”的方式，直接从Redis中读取该用户的余额“balance”数据。
===4. 加载主页筛选面板的学科标签===
1）首先，MySQL中应当本就存在表info_paper_with_tag和表info_tag。“本就存在”这两个表是因为运维人员会手动使用DB_tools目录下的工具脚本将原始数据转换并存入MySQL数据库，而这一步不在也不应该在生产环境的server进程中被自动执行。
表info_paper_with_tag和表info_tag的具体信息如下：
mysql> DESCRIBE info_paper_with_tag;
+-------+--------------+------+-----+---------+----------------+
| Field | Type         | Null | Key | Default | Extra          |
+-------+--------------+------+-----+---------+----------------+
| id    | int          | NO   | PRI | NULL    | auto_increment |
| Name  | varchar(255) | NO   | MUL | NULL    |                |
| Tag   | varchar(255) | NO   | MUL | NULL    |                |
+-------+--------------+------+-----+---------+----------------+
id: 映射关系唯一 ID (Primary Key, 自增)。
Name: 期刊缩写。
Tag: 对应的学科标签。
(Name + Tag 组合唯一)
内容示例：
mysql> select * from info_paper_with_tag limit 1;
+----+-------------------+------+
| id | Name              | Tag  |
+----+-------------------+------+
|  7 | ANNU REV NEUROSCI | 医学 |
+----+-------------------+------+
mysql> DESCRIBE info_tag;
+---------+--------------+------+-----+---------+-------+
| Field   | Type         | Null | Key | Default | Extra |
+---------+--------------+------+-----+---------+-------+
| tag     | varchar(255) | NO   | PRI | NULL    |       |
| tagtype | varchar(255) | NO   |     | NULL    |       |
+---------+--------------+------+-----+---------+-------+
tag: 学科标签名 (Primary Key)。
tagtype: 标签类型 (如 "一级分类", "二级分类")。
内容示例：
mysql> select * from info_tag limit 1;
+----------------------+----------+
| tag                  | tagtype  |
+----------------------+----------+
| 中世纪与文艺复兴研究 | 二级分类 |
+----------------------+----------+
2）Redis容器建起后，后台进程运行脚本对Redis初始化，将MySQL中的这两个表（info_paper_with_tag和info_tag）存入Redis，并本地持久化存储。Redis中，这部分数据的存储方式：
a. **标签元数据 (Hash)**:
Key: `sys:tags:info`
Field: "医学" -> Value: "一级分类"
Field: "计算机科学" -> Value: "一级分类"
b. **标签-期刊反向索引 (Set)**:
Key: `sys:tag_journals:{Tag}`
例如 Key: `sys:tag_journals:医学` -> Value: {"ANNU REV NEUROSCI", "LANCET", ...}
c. **优势**: Set 结构支持 `SINTER` (交集)，方便实现“医学 AND 2024”的快速筛选。
3）最后，在生产环境的正常业务流程中，server进程直接访问Redis中`sys:tags:info` 和 `sys:tag_journals:{Tag}` 数据（不能访问MySQL），可频繁读写数据。
===5. 根据标签筛选并返回期刊列表===
这一步中，用户会在index主页中选定需要的期刊，并选定年份范围（例如2023-2025年）。
1）首先，MySQL中应当本就存在表contentlist。“本就存在”这两个表是因为运维人员会手动使用DB_tools目录下的工具脚本将原始数据转换并存入MySQL数据库，而这一步不在也不应该在生产环境的server进程中被自动执行。
表contentlist的具体信息如下：
mysql> DESCRIBE contentlist;
+------------+--------------+------+-----+---------+-------+
| Field      | Type         | Null | Key | Default | Extra |
+------------+--------------+------+-----+---------+-------+
| Name       | varchar(255) | NO   | PRI | NULL    |       |
| FullName   | text         | YES  |     | NULL    |       |
| DataRange  | text         | YES  |     | NULL    |       |
| UpdateDate | text         | YES  |     | NULL    |       |
| Price      | int          | YES  |     | NULL    |       |
+------------+--------------+------+-----+---------+-------+
Name: 期刊/会议缩写 (Primary Key)。
FullName: 期刊/会议全名。
DataRange: 该期刊包含的数据年份范围。
UpdateDate: 数据的最后更新日期。
Price: 该期刊每篇文章的基础检索点价格。
内容示例：
mysql> select * from contentlist limit 1;
+-------------------+-------------------------------+-----------+------------+-------+
| Name              | FullName                      | DataRange | UpdateDate | Price |
+-------------------+-------------------------------+-----------+------------+-------+
| ANNU REV NEUROSCI | Annual Review of Neuroscience | 2016-2025 | 10/31/2025 |     2 |
+-------------------+-------------------------------+-----------+------------+-------+
2）Redis容器建起后，后台进程运行脚本对Redis初始化，将MySQL中的表contentlist存入Redis，并本地持久化存储。Redis中，这部分数据的存储方式：
a. **期刊基础信息 (Hash)**:
Key: `sys:journals:info`
Field: "ANNU REV NEUROSCI" -> Value: JSON `{"FullName":..., "DataRange":...}`
b. **期刊价格表 (Hash)**:
Key: `sys:journals:price`
Field: "ANNU REV NEUROSCI" -> Value: "2" (Integer)
（独立存储价格是为了 Worker 扣费时能以 O(1) 极速读取，无需解析大 JSON）。
3）最后，在生产环境的正常业务流程中，server进程直接访问Redis中`sys:journals:info` 和 `sys:journals:price` 数据（不能访问MySQL），可频繁读写数据。
===6. 估算选中期刊和年份的文献总数及费用===
用户在完成上一步“5. 根据标签筛选并返回期刊列表”之后，紧接着在这一步中，用户会点击“更新统计”按钮。系统会从Redis中读取数据（不能访问MySQL），然后估算选中期刊和年份的文献总数及费用。
1）关于新增表contentlist_year_number。
++++++新增表contentlist_year_number的初步想法（开始）++++++
S1）MySQL中先新增一个表“contentlist_year_number”，包含2个列：Name和YearNumber。仍然和contentlist表一样以Name作为主键。而YearNumber这一列中用一个完整的字符串存储每一年包含的文献篇数信息。
例如：
"2016:120,2017:252,2018:325,2019:663"
其中，英文冒号“:”的左侧数字表示年份，右侧数字表示该刊物在该年份总共包含的文献篇数。
S2）在DB_TOOL目录中，新增一个脚本，用于将每个刊物的每个年份包含的文献篇数统计后，以上述格式记录在新增的表“contentlist_year_number”中。
S3）MySQL的表“contentlist_year_number”在Redis初始化时就要被写入Redis。使用String数据格式存储每一条的整个对象（用JSON或者Hash？我不确定，请AI来分析决定）。 例如该表中的第1条数据（示例数量是编的）：
SET contentlist_year_number:ANNU REV NEUROSCI '{"2016":"120","2017":"252","2018":"325","2019":"663"}'
S4）在生产环境的正常业务流程中，server进程直接从Redis的“与MySQL表contentlist_year_number对应”的数据中读取所选待查刊物对应的年份范围包含的总文献数量，
再结合Redis中“与MySQL表contentlist对应”的数据中所选刊物的“Price”，用以计算待查文献总篇数和消耗检查点的数量。
++++++新增表contentlist_year_number的初步想法（结束）++++++
===7. 用户正式提交任务===
用户点击“开始检索”按钮以正式向服务器提交开始查询任务的请求。任务进入Redis的“查询任务的消息队列”。
Redis中应当有这么一个“查询任务的消息队列”需要被设计出来，具体如下：
1）**任务队列结构**:
Key: `task:{uid}:{qid}:pending_blocks` (List)
Value: Block Key (例如 `meta:NATURE:2024`)
2）**作用**:
- 分发线程将大 Query 拆解为多个 Block Key 推入此队列。
- Worker 线程从这里 `LPOP` 抢占任务。
3）**优势**: 实现了任务粒度的细化和多 Worker 的负载均衡。
===8. 任务分发线程从消息队列领取任务，然后分配给多线程并发的“工人线程”，以执行具体的查询任务===
server进程中应该有一个“查询任务分发线程”，意为用于将消息队列里的查询任务分发出去的线程。只要步骤7中提到的Redis的“查询任务的消息队列”中还有任务，那么“查询任务分发线程”就应当按照“查询任务执行规则”将任务依次取出，分配给多线程并发的“工人线程”，“工人线程”执行具体的查询任务。
server进程中应该有一个“工人线程生产器”来根据“查询任务执行规则”生产“工人线程”。
server进程中应该有一个“工人线程统计器”来实时统计当前存在的工人线程数量，并拥有返回“当前存在的工人线程数量”的功能。
server进程中应该有一个“TPM累加器”：工人线程每次收到来自远端AI返回的消息时，都可以通过“tokens = response.usage.total_tokens”获取本次对话消耗的总token数量（参考“lib\process\search_paper.py”中的代码是怎么写的）。response.usage.total_tokens会返回一个数值，该数值表示本次对话消耗的总token数量。每个工人线程只要收到了本次对话消耗的总token数量，就应该立即将它发送给“TPM累加器”。“TPM累加器”的职责是以1秒为时间周期，统计该周期内收到的来自所有工人线程发送的tokens数值的总和，然后将汇总后的数值立刻发送给“TPM滑动窗口”，发送完成后“TPM累加器”清空内部数据，重新统计下一秒的时间周期内收到的tokens数值的总和，以此循环往复。
+++系统资源计算器+++
server进程中应该有一个“系统资源计算器”来计算当前系统的1）实时TPM（整个系统每分钟消耗的Token总数，这个总数包含发送和接收的Tokens）；2）实时RPM（整个系统每分钟向AI发送的请求总数）。
实时TPM和实时RPM以“滑动窗口”的方式进行统计：
a）“TPM滑动窗口”：存在一个容量为60个单位的队列，从队列的第一个单位（队首）开始，每单位存放1秒间隔内整个系统使用的总Token数量。
在60个单位的队列未被填满时，队列中所有单位内存储的token数量之和就是当前的“系统已使用TPM”。
随着第60个数据加入到队尾单位，全部60个单位的队列被填满，此后，对于新来的数据，队列挤出队首单位内的数值（排出最旧的数据），剩下的队列整体向前移动一个单位，最后新数据加入队尾空出来的单位中。
全部60个单位的队列被填满时，队列中所有单位内存储的token数量之和就是当前的“系统已使用TPM”。
b）“RPM滑动窗口”：和TPM滑动窗口一样，但每单位的数据不一样，存放的是1秒间隔内整个系统整个系统向远端AI发送的请求总次数。
滑动窗口队列示意图：
(队首)[0-1][1-2][2-3]......[59-60](队尾)
++++++
++++++查询任务执行规则（开始）++++++
规则R1）如果“查询任务分发线程”要从“查询任务的消息队列”中取出一个任务（这里简称为“队首任务”），且想要开始分配该任务给工人线程，那么它必须向“工人线程生产器”请求产生工人线程。工人线程生产器收到请求后，根据“规则R2”决定是否要生产指定数量的工人线程。
规则R2）只有当前系统剩余资源高于"队首任务"所需的资源时，工人线程生产器才能生产"队首任务"对应的用户（uid）所拥有的权限（permission）数值相同的工人线程。例如，假设当前系统剩余资源高于"队首任务"所需的资源，此时"队首任务"的用户的permission是2，那么工人线程生产器就要生产2个工人线程，否则一个也不能生产。
**补充（2025-11-27）**：实际启动的Worker数量 = min(permission, 待处理Block数量)。当Block数量少于permission时，只启动与Block数量相等的Worker，避免资源浪费（多余的Worker会因为队列为空而立即退出）。此规则同时适用于普通查询任务和蒸馏任务。
规则R3）每个工人线程在向远端AI发送Prompt后（即发送了一个请求后），要等待远端AI的回复消息。只有在收到回复的消息之后，才能继续下一轮发送请求。
规则R4）工人线程的生命周期与任务粒度（采用任务池+抢占模式）：
a) **任务拆解**：当“查询任务分发线程”决定开始执行一个 Query（队首任务）时，它首先将该 Query 拆解为若干个 Block Key（例如 "meta:NATURE:2024"），并将这些 Key 放入该 Query 专属的 Redis List（Key: `task:{uid}:{qid}:pending_blocks`）。
b) **线程启动**：分发线程根据用户的 permission（例如 2）启动对应数量（2个）的 Worker 线程。这些 Worker 线程被标记为服务于该 `query_index`。
c) **抢占执行**：每个 Worker 线程进入一个 `while` 循环：
i. **检查暂停信号**：读取 Redis `query:{uid}:{qid}:pause_signal`。
- 若存在：将手中已取出的 Block（如果有）推回队列 (`LPUSH`)，然后线程**自动退出销毁**。
- 若不存在：继续下一步。
ii. **领取任务**：从 `task:{uid}:{qid}:pending_blocks` 中 `LPOP` 一个 Block Key。
- 如果取到了 Block：执行 R5 规则进行处理。
- 如果 List 为空：说明该 Query 所有 Block 已被领取完毕，Worker 线程自动退出（销毁）。
d) **优势**：这种模式下，Worker 自动实现了“续命”，且并发数严格受控于 permission；同时支持快速响应暂停指令，释放系统资源。
规则R5）工人线程执行的具体流程与数据获取：
a) **获取数据**：Worker 接收到 `Block Key`（如 `meta:NATURE:2024`）后，执行 Redis `HGETALL {Block Key}`，一次性拉取该 Block 下所有文献的 DOI 和 **原始 Bib 字符串**（Value 不再是 JSON，而是压缩后的 Bib）。
b) **解析与构造**：Worker 在内存中解析 Bib 字符串，提取 Title、Abstract 等字段。对于每一篇文献：
i. 构造 Prompt（包含用户问题 + 摘要）。
ii. 调用 AI API（遵守 R3，同步等待）。
iii. 获取 `tokens` 消耗，上报给“TPM 累加器”。
c) **结果写入与原子扣费**：收到 AI 判定结果后，Worker 执行以下原子操作（Lua 脚本）：
i. 获取当前 Block 对应刊物的单价 $P$（从 `sys:journals:price`）。
ii. 检查 `user:{uid}:balance` 是否 >= $P$。
iii. 若足额：
- `DECRBY user:{uid}:balance $P`（实时扣费）。
- `HSET result:{uid}:{query_index} {DOI} {JSON_Result}`（写入结果）。
- `RPUSH billing_queue:{uid} {timestamp, qid, doi, cost: $P}`（写入消费流水）。
iv. 若余额不足：标记该任务失败/跳过，不写入结果也不扣费。
d) **进度更新**：Worker 每处理完一篇，执行 Redis `HINCRBY progress:{uid}:{query_index}:finished_count 1`，用于前端进度条显示。当整个 Block 处理完后，执行 R6 规则进行完成判定。
规则R6）查询任务完成判定与状态流转：
a) **初始化**：Query 启动时，分发线程计算总 Block 数，写入 `total_blocks` 到 Redis `query:{qid}:status` Hash 中。
b) **原子计数**：Worker 每处理完一个 Block，执行 `HINCRBY query:{qid}:status finished_blocks 1`。
c) **完成判定**：Worker 检查 `finished_blocks` 是否等于 `total_blocks`。
- 如果相等：该 Worker 负责将 Query 状态标记为 `DONE`，并触发“异步归档”流程（见下文持久化策略），然后销毁。
- 如果不等：继续循环领取下一个 Block。
++++++查询任务执行规则（结束）++++++
2）关于重构表paperinfo
首先，MySQL中应当本就存在表paperinfo。“本就存在”这两个表是因为运维人员会手动使用DB_tools目录下的工具脚本将原始数据转换并存入MySQL数据库，而这一步不在也不应该在生产环境的server进程中被自动执行。
+++新架构的表paperinfo需要被重构（具体陈述开始）+++
MySQL的表paperinfo需要被重构，DB_tools目录下构建表paperinfo的工具脚本也要被完全重写。
***在旧架构中***
在旧架构中，该表用于存储所有的原始文献数据。其中Bib存放了该条文献的完整Bib信息。其余的列，例如Name\Year\Title\DOI等都是为了旧架构中方便服务进程直接读取指定数据而建的。
***在新架构中***
新架构中，在查询每一条文献内容的阶段时，不再从MySQL查，转而只能从Redis查询。所以表paperinfo应当只保留Bib内容，把拆分出来的信息放入Redis中的新的存储结构内。
新架构中，仅仅保留2个列：DOI和BIB。其中DOI列为主键，其值来自于BIB内容（JSON格式）中的doi对应的内容。
+++新架构的表paperinfo需要被重构（具体陈述结束）+++
3）Redis容器建起后，后台进程运行脚本对Redis初始化，将MySQL中的表paperinfo存入Redis，并本地持久化存储。Redis中，这部分数据的存储方式：
++++++以block为最小查询任务的取用单位的提议（最终设计）++++++
基于数据量（500万篇）和内存（16GB）的评估，以及对查询/下载双重场景的支持，确定采用以下 Block 存储方案：
1）**Redis Key 设计**:
- 采用 Hash 结构。
- Key: `meta:<JournalName>:<Year>` (例如 `meta:ANNU REV NEUROSCI:2024`)。
2）**Field 与 Value**:
- **Field**: 文献 DOI (例如 `10.1007/s10055...`)。
- **Value**: **压缩后的原始 Bib 字符串**。
（不再存储 JSON 对象 `{"t":..., "a":...}`，而是直接存 Bib。因为 Bib 包含了 Title、Abstract、Author、Year 等所有元数据）。
3）**设计理由**:
- **内存效率**: Bib 格式紧凑，压缩后占用极小。500万篇约占 8-10GB，完全可加载进内存。
- **通用性**:
- **Worker 查询时**: 取出 Bib -> 解析出 Abstract -> 构造 Prompt -> 发送 AI。
- **用户下载时**: 取出 Bib -> 直接写入 .bib 文件（无需反向转换）。
- **IO 隔离**: 任务只传递 Block Key，Worker 自己去 Redis 取数据，避免了在消息队列中传递大体积文本。
4）**加载策略**:
- Redis 启动时，后台脚本从 MySQL `PaperInfo` 表全量加载数据到 Redis。
- 设置 TTL（如 7 天），配合 LRU 淘汰冷数据；Worker 遇到 Key Miss 时回源 MySQL 加载。
++++++以block为最小查询任务的取用单位的提议（结束）++++++
===9. 任务结果的持久化与下载流程===
1）**持久化策略**：
- **异步归档**：只有当 R6 规则判定 Query 状态变为 `DONE` 时，才启动一个独立的"归档线程"（或复用 Worker 最后一步），将 Redis 中的 `result:{uid}:{qid}` (Hash) 批量写入 MySQL 的 `search_result` 表（新表结构，不再分日期，而是大宽表或分区分表）。
- **MySQL 角色**：MySQL 仅作为冷数据备份和审计查询，不参与实时业务，避免 IOPS 瓶颈。
- **Result缓存TTL策略（2025-11-30新增）**：
  - `result:{uid}:{qid}` 设置 7天 TTL，防止 Redis 内存无限增长。
  - 按每日70,000篇查询量估算，稳态内存占用约 341MB。
  - 蒸馏功能若 Redis MISS（超过7天），自动从 MySQL `search_result` 表回源。
  - 回源方法：`get_relevant_dois_from_mysql(uid, query_id)` 位于 `lib/load_data/search_dao.py`。
2）**下载任务的消息队列**：
- **背景**：下载任务是 IO 密集型（读 Redis -> 写文件 -> 发送），与 CPU/GPU 密集型的 AI 查询任务性质不同。高并发场景下（如100个用户同时下载），同步处理会导致线程池耗尽和请求超时。
- **设计**：建立独立的 `download_queue`（Redis List），以及独立的 `DownloadWorker` 线程池（默认10个Worker）。
3）**下载流程详解**：
a. **用户请求**：点击"下载CSV"或"下载Bib" -> API 创建下载任务 -> 立即返回 `task_id`。
b. **任务入队**：`RPUSH download_queue {task_id, uid, qid, type, timestamp}`。
c. **前端轮询**：每秒调用 `GET /api/download/status?task_id=xxx` 查询任务状态。
d. **Worker处理**：`DownloadWorker` 从队列 `LPOP` 任务，执行以下操作：
   - 更新任务状态为 `PROCESSING`。
   - **使用 Redis Pipeline 批量获取**：收集所有 block_key，一次性获取所有 Bib 数据。
   - 在内存中生成 CSV 或 Bib 文件。
   - 将文件内容存入 Redis 临时缓存 `download:{task_id}:file`（TTL 5分钟）。
   - 更新任务状态为 `READY`。
e. **文件下载**：前端检测到状态为 `READY` 后，调用 `GET /api/download/file?task_id=xxx` 获取文件内容。
4）**Redis Key 设计**：
- **下载队列**: `download_queue` (List) - 全局下载任务队列。
- **任务状态**: `download:{task_id}:status` (Hash) - 字段包括 {state, uid, qid, type, created_at}。
  - state 取值: `PENDING`（待处理）、`PROCESSING`（处理中）、`READY`（已就绪）、`FAILED`（失败）。
- **文件内容**: `download:{task_id}:file` (String) - 生成的文件内容，TTL 5分钟。
5）**性能优化：批量获取**：
- **核心优化**：使用 Redis Pipeline 批量获取 Block 数据，将 O(n) 次网络往返优化为 O(1) 次。
- **实现方式**：Worker 先遍历所有结果收集 block_key 列表，然后使用 Pipeline 执行批量 HGETALL，最后组装结果。
- **性能对比**（1000篇文献，每次Redis往返10ms）：
  - 逐个获取：1000 × 10ms = 10秒
  - Pipeline批量获取：1次 × 50ms ≈ 50毫秒
6）**高并发场景分析**：
- **DownloadWorker池大小**：默认10个Worker。
- **100用户并发下载**（每人1000篇）：
  - 请求响应：立即返回 task_id（<100ms）。
  - 平均等待：(100/10) × 2秒 / 2 = 10秒。
  - 最长等待：(100/10) × 2秒 = 20秒。
- **优势**：
  - **用户请求不阻塞**：立即返回任务ID，不占用Web Server线程。
  - **并发控制**：Worker池限制最大并发，保护 Redis IOPS 和网络带宽。
  - **资源隔离**：下载任务与查询/蒸馏任务使用独立的 Worker 池。
7）**API接口设计**：
- `POST /api/download/create` - 创建下载任务
  - 请求：`{query_id, type: "csv"|"bib"}`
  - 响应：`{success: true, task_id: "..."}`
- `GET /api/download/status?task_id=xxx` - 查询任务状态
  - 响应：`{state: "PENDING"|"PROCESSING"|"READY"|"FAILED", progress: 0-100}`
- `GET /api/download/file?task_id=xxx` - 下载文件
  - 响应：文件内容（Content-Disposition 头）
- **兼容旧API**：保留 `/api/download_csv` 和 `/api/download_bib`，内部调用新机制并同步等待。
===10. 安全与多用户隔离设计（安全修正案）===
为了防止多用户环境下的数据串扰（如用户 B 下载用户 A 的结果），必须强制执行以下隔离规范：
1）**Redis Key 命名空间隔离**：
- 严禁使用全局 ID 作为 Key 的唯一标识。
- 所有与用户数据相关的 Key 必须前缀 `{uid}`。
- 修正后的 Key 规范：
- 任务状态: `query:{uid}:{qid}:status` (原 `query:{qid}:status`)
- 结果存储: `result:{uid}:{qid}` (原 `result:query:{qid}`)
- 任务队列: `task:{uid}:{qid}:pending_blocks` (原 `task:query:{qid}:...`)
- 进度条: `progress:{uid}:{qid}:finished_count` (原 `progress:query:{qid}:...`)
2）**下载权限强校验**：
- 在将下载请求放入 `download_queue` 之前，API 层必须校验：当前登录用户的 `session.uid` 是否等于请求参数中的 `uid`。
- `DownloadWorker` 从队列取出任务（包含 `uid` 和 `qid`）后，在读取 Redis 数据时，必须拼接 `{uid}` 前缀（例如读取 `result:{uid}:{qid}`）。
- 效果：即使恶意用户 B 猜到了 A 的 `qid`，但他构造的下载请求要么被 API 层拦截（uid 不匹配），要么在 Worker 层因为 Key 拼接了 B 的 uid 而读不到数据（Redis 中不存在 `result:B:{qid_of_A}`），从而物理上杜绝了越权访问。
===11. 高效余额扣费与持久化设计（Billing System）===
为了平衡“高性能扣费”与“资金安全”，采用 **Redis 实时扣费 + 异步流水对账** 模式：
1）**数据准备**：
- 在步骤 5（加载 ContentList 到 Redis）时，必须同步加载 `price` 信息。
- 结构: `sys:journals:price` (Hash) -> Field: `ANNU REV NEUROSCI`, Value: `2`。
2）**消费流水队列 (`billing_queue:{uid}`)**：
- 这是一个 Redis List，记录每一次成功的扣费操作。
- 作用：作为 Write-Ahead Log (WAL)，即使 Redis 发生故障，只要 AOF 开启，流水记录就不会丢失，可用于重建余额或审计。
3）**后台对账线程 (`BillingSyncer`)**：
- **职责**：负责将 Redis 中的消费流水批量同步到 MySQL，确保数据库余额最终一致。
- **流程**：
a. 循环扫描所有活跃用户的 `billing_queue:{uid}`。
b. 取出一批流水记录（例如 100 条），计算总扣费金额 `total_deduct`。
c. 执行 MySQL 事务：`UPDATE user_info SET balance = balance - total_deduct WHERE uid = ...`。
d. 只有当 MySQL 更新成功后，才从 Redis Queue 中截断（Trim）已同步的记录。
- **优势**：MySQL 承受的是聚合后的低频更新（如每秒 1 次），而不是 Worker 产生的高频更新（如每秒 1000 次），极大保护了数据库性能。
===12. 废弃功能与变更说明===
1）**废弃“删除历史记录”功能**：
- **决策**：新架构彻底移除 `delete_query` / `hide_query` 相关接口与逻辑。
- **理由**：
- **审计合规**：防止用户通过删除记录规避扣费审计。
- **架构简化**：减少 Redis/MySQL 中维护 `is_visible` 状态的复杂度。
- **数据完整性**：保证所有 `query_log` 和 `billing_log` 永久可追溯。
===13. 任务暂停与恢复设计===
在旧架构中，暂停是通过修改 MySQL `query_log.should_pause` 字段实现的。新架构中，采用基于 Redis Key 的“信号灯”机制：
1）**信号灯设计**：
- Key: `query:{uid}:{qid}:pause_signal` (String, Value="1")。
- 存在即表示“暂停中”，不存在即表示“正常运行”。
2）**暂停流程**：
- 用户点击“暂停” -> API 设置 `pause_signal`。
- **Worker 响应**（修正 R4 规则）：
- Worker 在 `LPOP` Block 之前，先检查 `pause_signal` 是否存在。
- **若存在**：
1. 将该 Worker 手中已取出但尚未开始处理的 Block（如果有）推回队列头部 (`LPUSH`)。
2. Worker 线程直接**结束运行并销毁**。
- **结果**：该任务占用的 CPU/内存资源被完全释放，仅保留 Redis 队列中的待处理 Block。
3）**恢复流程**：
- 用户点击“继续” -> API 删除 `pause_signal` -> API 重新调用“分发器”逻辑。
- 分发器检测到该 Query 还有 `pending_blocks`，根据 permission 重新生产新的 Worker 线程继续消费。
4）**僵尸任务处理**：
- 为防止用户暂停后永远不恢复，可为 `pause_signal` 设置 TTL（如 7 天）。过期后，配合定期清理脚本将长期未动的任务标记为“已终止”并清理队列。
===13.5 任务终止 (Terminate) 设计 (新增)===
区别于“暂停”的软性停止，“终止”是强制且不可恢复的操作：
1）**信号设计**：
- Key: `query:{uid}:{qid}:terminate_signal` (String, Value="1", TTL 7天)。
- 优先级高于 `pause_signal`。
2）**终止流程**：
- 用户/管理员点击“终止” -> API 设置 `terminate_signal`。
- API 将任务状态设为 `CANCELLED` 并清空 `pending_blocks` 队列。
- API 调用 `stop_workers_for_query` 向所有活跃 Worker 发送信号。
3）**Worker 响应**：
- Worker 循环中检测到 `terminate_signal`。
- 立即停止当前处理，**不**将手中的 Block 推回队列。
- 打印“收到终止信号”日志并退出销毁。
===14. 蒸馏任务业务全流程设计===
蒸馏任务本质上是一个“输入范围受限”的查询任务。它复用大部分查询架构，但在数据源和计费上有所不同。
1）**数据源与复用**：
- 普通查询范围 = 用户选择的刊物 x 年份（Blocks）。
- 蒸馏查询范围 = 上一次任务（父任务）中判定为“相关”的文献集合。
- **策略**：利用 Redis `result:{uid}:{parent_qid}` Hash 中存储的 `JSON_Result`（或隐含的 DOI），以及 Redis Block 中存储的原始 Bib。
- *修正*：由于 `result` Hash 中只存了 AI 结果 JSON，Worker 蒸馏时仍需获取 Bib/Abstract。建议 Worker 在蒸馏时，根据 DOI 反查 `meta:BlockKey`（需建立 DOI->BlockKey 的映射，或遍历），或者更简单的：**在普通查询的 `result` Hash 中，Value 建议冗余存储 Bib 摘要，或者在 `result` Hash 中存储 BlockKey**。
- *推荐*：`result:{uid}:{qid}` 的 Value 结构升级为 `{"ai_result": ..., "block_key": "meta:..."}`。这样蒸馏时，Worker 拿到 DOI 后可直接获取 BlockKey，再从 Block Hash 中读取 Bib。
2）**蒸馏任务队列**：
- 复用 `task:{uid}:{qid}:pending_blocks` 结构。
- 但其中的“Block”不再是刊物年份 Key，而是**临时生成的 DOI 分片（Distill Chunk）**。
- Key: `distill_chunk:{uid}:{qid}:{chunk_id}` (List)，存储本批次待蒸馏的 DOI 列表。
- **API 参数修正**：发起蒸馏时，必须使用 `original_query_id` (String) 而非 `query_index` (Int)，因为新架构 Query ID 为字符串格式。
3）**流程设计**：
- **A. 估算**：
- 读取 `result:{uid}:{parent_qid}` 中所有 `search_result=1` 的 DOI。
- 统计数量 $N$。
- 估算费用 $Cost = N \times Price \times 0.1$。
- **B. 提交**：
- 创建新 `query_log`（`is_distillation=1`）。
- 将 $N$ 个 DOI 按每 100 个分片，存入 `distill_chunk:{uid}:{qid}:{chunk_id}`。
- 将 Chunk Key 推入 `task:{uid}:{qid}:pending_blocks`。
- 启动分发器（Worker数量同样遵循规则R2补充：实际启动Worker数 = min(permission, Chunk数量)）。
- **C. Worker 执行**：
- Worker 识别任务类型（Distillation，通过 Key 前缀或 metadata）。
- `LPOP` 一个 `distill_chunk` Key。
- 遍历 Chunk 中的 DOI：
- 从 `result:{uid}:{parent_qid}` 获取该 DOI 的 `block_key`。
- 从 `meta:{block_key}` 获取 Bib/Abstract。
- 执行 AI 判断。
- **扣费**：应用 0.1 倍费率，流程同 Billing System。
===15. 部署架构与网络拓扑===
1) **网络架构**:
- **DNS**: 阿里云解析 -> ECS 公网 IP
- **ECS**:
- **Nginx**: 80/443 端口，负责静态文件服务、SSL 终止、API 反向代理。
- **Backend**: Docker 容器，运行 Python 业务进程。
- **Redis**: Docker 容器，仅监听 127.0.0.1，不暴露公网。
- **RDS MySQL**: 通过 VPC 内网连接，不暴露公网。
2) **安全组策略**:
- ECS 安全组仅开放 80 (HTTP), 443 (HTTPS), 22 (SSH)。
- 屏蔽 Redis (6379) 和 MySQL (3306) 的公网访问。
3) **负载均衡**:
- 当前阶段不使用 SLB，直接通过 ECS 公网 IP 访问。SSL 证书部署在 ECS 的 Nginx 上。
===16. 新版管理员系统设计===
1) **账户隔离策略**:
- **MySQL**: 新增 `admin_info` 表 (uid, username, password, role, created_at)，物理隔离于 `user_info`。
- **Redis**: 使用 `admin:session:{token}` 存储会话，`admin:{uid}:info` 存储热点数据。
2) **访问控制**:
- **独立登录**: 新增 `/admin/login.html`，调用 `/api/admin/login`。
- **中间件鉴权**: 后端中间件严格区分 `/api/admin/*` (查 admin session) 和 `/api/*` (查 user session)。
3) **功能模块设计**:
- **用户管理**: 列表展示、余额充值/扣除、权限调整、账号封禁。
- **管理员管理**: 超级管理员可增删普通管理员。
- **系统监控大盘**:
- **任务监控**: 实时 TPM/RPM (滑动窗口)、Redis 队列积压数、活跃 Worker 数。
- **健康监控**: Redis/MySQL 连接状态、Billing Queue 积压报警。
- **系统控制**: 新增 `control.html` 页面，提供“用户注册开关”等全局配置的实时切换 (API: `/api/admin/toggle_registration`)。
4) **废弃**:
- 删除 `AutoPaperSearchControlPanelAdmin.html`。
- 移除所有未经过鉴权的旧版管理接口。
===17. DB_tools 重构与数据库初始化流程===
在新架构中，`DB_tools` 目录将从“手动辅助工具集”转变为“标准化数据库初始化套件”。旧有的多个分散脚本将被整合并重写，以支持自动建表、数据导入、数据清洗和统计。
### 17.1 废弃说明
以下旧组件和概念将被彻底废弃：
1. **表 `sentence`**: 彻底移除。新架构直接在 Redis Block 中存储完整 Bib，Worker 内存解析 Abstract，无需再拆解为句子存储。
2. **表 `api_usage_minute`**: 彻底移除。流控统计改为内存滑动窗口（TPM/RPM）。
3. **表 `app_settings`**: 彻底移除。静态配置走 `config.json`，动态业务数据走 Redis。
4. **表 `task_queue`**: 彻底移除。任务队列完全由 Redis List 接管。
5. **脚本 `tools_refresh_db_sentence.py`**: 废弃。
6. **README.md 中的手动 SQL 建表命令**: 废弃。所有建表操作将由 Python 脚本自动完成。
### 17.2 新工具设计：`init_database.py`
我们将创建一个统一入口脚本 `init_database.py`，它负责按正确顺序调用内部模块完成数据库初始化。
**目录结构建议**:
```
DB_tools/
├── init_database.py        # 主入口脚本
├── config.json             # 数据库连接配置
├── requirements.txt        # 依赖包 (mysql-connector-python, bibtexparser)
├── lib/                    # 内部模块库
│   ├── db_schema.py        # 定义所有 CREATE TABLE SQL
│   ├── loader_bib.py       # Bib文件解析与导入 (ContentList, PaperInfo, YearNumber)
│   ├── loader_tags.py      # 标签与映射导入 (InfoTag, InfoPaperWithTag)
│   └── loader_api.py       # API Key 导入 (ApiList)
├── Data/                   # 存放 .bib 原始数据的文件夹 (按期刊名命名)
├── PaperAndTagInfo/        # 存放 CSV 元数据 (InfoList.Paper.csv 等)
└── APIKey/                 # 存放 API Key 文本文件
```
### 17.3 数据库初始化流程
运维人员只需配置好 `config.json` 并放入数据文件，然后运行 `python init_database.py`。脚本将自动执行以下步骤：
**Step 1: 基础表结构创建 (`db_schema.py`)**
- 连接 MySQL，设置会话字符集为 `utf8mb4`。
- 自动创建以下表（若不存在）：
- `user_info`: 用户表 (uid, username, password, balance, permission)
- `admin_info`: 管理员表 (uid, username, password, role)
- `api_list`: API 密钥表 (api_key, limit)
- `contentlist`: 期刊元数据表 (Name, FullName, DataRange, Price)
- `contentlist_year_number`: **[新增]** 年份统计表 (Name, YearNumberJson)
- `paperinfo`: **[重构]** 文献表 (DOI, Bib) —— *极大精简，仅存 Bib JSON*
- `info_tag`: 标签表 (Tag, TagType)
- `info_paper_with_tag`: 映射表 (Name, Tag)
- `query_log`: 任务记录表 (归档用)
- `search_result`: 结果记录表 (归档用)
**Step 2: API Key 导入 (`loader_api.py`)**
- 扫描 `APIKey/` 目录，去重导入 `api_list` 表。
**Step 3: 期刊与文献导入 (`loader_bib.py`)**
- 读取 `PaperAndTagInfo/InfoList.Paper.csv`，更新 `contentlist` 表的基础信息。
- 遍历 `Data/` 目录下的子文件夹（期刊名）：
- 解析每个 `.bib` 文件。
- **构建 PaperInfo**: 提取 DOI 和完整 Bib 字符串，封装为 JSON (`{"bib": "..."}`) 存入 `paperinfo` 表。*注意：不再拆解 Title/Author/Abstract 为独立列，全部压入 Bib 字段（或直接存 JSON）。鉴于 MySQL 性能，建议 `PaperInfo` 表结构为 `DOI VARCHAR(255) PK, Bib JSON`。*
- **统计年份数据**: 在内存中累计该期刊每个年份的文献数量。
- **写入统计**: 将统计结果（如 `{"2023": 150, "2024": 200}`）序列化为 JSON，写入 `contentlist_year_number` 表。
**Step 4: 标签导入 (`loader_tags.py`)**
- 读取 `InfoList.Tag.csv`，全量同步 `info_tag` 表。
- 读取 `InfoList.PaperWithTag.csv`，导入 `info_paper_with_tag` 表。
### 17.4 关键表 SQL 定义 (Reference)
```sql
-- 1. 用户表
CREATE TABLE IF NOT EXISTS user_info (
uid INT AUTO_INCREMENT PRIMARY KEY,
username VARCHAR(255) NOT NULL UNIQUE,
password VARCHAR(255) NOT NULL,
balance DECIMAL(10, 2) DEFAULT 0.00,
permission INT DEFAULT 0,
created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
-- 2. 管理员表
CREATE TABLE IF NOT EXISTS admin_info (
uid INT AUTO_INCREMENT PRIMARY KEY,
username VARCHAR(255) NOT NULL UNIQUE,
password VARCHAR(255) NOT NULL,
role VARCHAR(50) DEFAULT 'admin',
created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
-- 3. 期刊列表
CREATE TABLE IF NOT EXISTS contentlist (
Name VARCHAR(255) PRIMARY KEY,
FullName TEXT,
DataRange TEXT,
UpdateDate TEXT,
Price INT DEFAULT 1
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
-- 4. 期刊年份统计 (新增)
CREATE TABLE IF NOT EXISTS contentlist_year_number (
Name VARCHAR(255) PRIMARY KEY,
YearNumberJson JSON COMMENT '格式: {"2023": 100, "2024": 50}'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
-- 5. 文献表 (重构)
CREATE TABLE IF NOT EXISTS paperinfo (
DOI VARCHAR(255) PRIMARY KEY,
Bib JSON NOT NULL COMMENT '包含完整 BibTex 字符串及元数据'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
-- 6. 标签表
CREATE TABLE IF NOT EXISTS info_tag (
Tag VARCHAR(255) PRIMARY KEY,
TagType VARCHAR(255) NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
-- 7. 标签映射表
CREATE TABLE IF NOT EXISTS info_paper_with_tag (
id INT AUTO_INCREMENT PRIMARY KEY,
Name VARCHAR(255) NOT NULL,
Tag VARCHAR(255) NOT NULL,
UNIQUE KEY uniq_name_tag (Name, Tag),
INDEX idx_tag (Tag)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
-- 8. 任务日志 (归档)
CREATE TABLE IF NOT EXISTS query_log (
query_id VARCHAR(64) PRIMARY KEY,
uid INT NOT NULL,
search_params JSON,
start_time DATETIME,
end_time DATETIME,
status VARCHAR(50),
total_cost DECIMAL(10, 2),
INDEX idx_uid (uid)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
-- 9. 搜索结果 (归档)
CREATE TABLE IF NOT EXISTS search_result (
id BIGINT AUTO_INCREMENT PRIMARY KEY,
uid INT NOT NULL,
query_id VARCHAR(64) NOT NULL,
doi VARCHAR(255) NOT NULL,
ai_result JSON,
created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
INDEX idx_query (query_id),
INDEX idx_uid (uid)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
-- 10. API 列表
CREATE TABLE IF NOT EXISTS api_list (
api_index INT AUTO_INCREMENT PRIMARY KEY,
api_key VARCHAR(512) NOT NULL UNIQUE,
api_name VARCHAR(255),
rpm_limit INT DEFAULT 3000,
tpm_limit BIGINT DEFAULT 500000,
is_active TINYINT(1) DEFAULT 1
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
```
